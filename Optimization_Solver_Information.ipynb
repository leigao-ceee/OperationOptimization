{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCHP System Operation Optimization Under Uncertainty\n",
    "### 0. Problem Statement\n",
    "\n",
    "### 1. Pyomo Solver Work Process\n",
    "    Pyomo will first define a SolverMangagerFactory locally (serial) or remotely(neos, pyro..), if not specified then use local solver, under the local solver, it specifies the interface(asl, gams), if not specified, search the solver in PATH, if not in PATH, then asl interface will be used.\n",
    "    \n",
    "    pip install in C:\\Users\\leigao\\AppData\\Local\\Continuum\\anaconda3\\Lib\\site-packages\\pyomo\n",
    "    conda install in C:\\Users\\leigao\\AppData\\Local\\Continuum\\anaconda3\\pkgs\n",
    "    The packages in the Anaconda2/Lib/site-packages folder is where Python looks to import packages. The packages in the Anaconda2/pkgs folder are the packages that are downloaded and extracted by Conda when you specify an update or install.\n",
    "    https://conda.io/projects/conda/en/latest/user-guide/configuration/use-condarc.html?highlight=symlink#disallow-soft-linking-allow-softlinks\n",
    "### 2. Model Details\n",
    "    There are total (26*Scen) *stage variables: 6864\n",
    "    There are total (5) *stage integel variables: 120\n",
    "    There are total (20*Scen)  *stage constraints: 5280\n",
    "##### 2.1 Simple one\n",
    "    There is no on-off signal, all components' PRL should be decided the before second stage, except grid and battery.\n",
    "    There are total (14*Scen+10) *stage variables: 3936\n",
    "    There are total (5+15*Scen)  *stage constraints: 4080\n",
    "### 3. Commertial Platform Limitation\n",
    "##### 3.1 GAMS: \n",
    "      300 of constraints and variables\n",
    "      2000 of nonzero elements (of which 1000 nonlinear)\n",
    "      50 of discrete variables (including semi continuous, semi integer and member of SOS-Sets)\n",
    "      Nonlinear: Number of constraints and variables: 10\n",
    "##### 3.2 AMPL:\n",
    "       there are similar restriction of demo version, but trail version has full function of 30 days.\n",
    "##### 3.3 BARON:\n",
    "       the variable and constraint limitation is 10 .\n",
    "### 4. Solver Details\n",
    "##### 4.1 MINLP solver: \n",
    "              AlphaECP(GN), AOA, ANTIGONE(GN), BARON(AGNPJ), Bonmin(AGNPJ), Couenne(AGNPJ), DICOPT(GN), Juniper(J),\n",
    "              Knitro(AGNPJ), LINDO(NPJ), Minotaur(A), Muriqui(A), Pavito(J), SBB(GN), SCIP(GNPJ), SHOT(G)\n",
    "##### 4.2 Open-Source: \n",
    "              Bonmin(GNPJ), Couenne(GNPJ), Juniper(J), Minotaur(A), Muriqui(A), Pavito(J), SCIP(GNPJ)\n",
    "##### 4.3 Global: \n",
    "              ANTIGONE(GN), BARON(AGNPJ), SCIP(GNPJ), LINDOGLOBAL(GN), COUENNE(GNPJ), Knitro(AGNPJ), Minotaur(A)\n",
    "##### 4.4 Other on neos: \n",
    "              FilMINT (https://www.swmath.org/software/6197), MINLP\n",
    "              Solver names recognized by neos:\n",
    "              ['bonmin', 'cbc', 'conopt(NL**)', 'couenne', 'cplex', 'filmint', 'filter', 'ipopt', 'knitro(NL**)', 'l-bfgs-b','lancelot(NL*)', 'loqo(NL)', 'minlp', 'minos(NL*)', 'minto(MILP)', 'mosek(MILP)', 'ooqp(LP)', 'path', 'snopt(NL**)']\n",
    "         \n",
    "##### 4.5 Soler Analysis of different solver:\n",
    "    https://scicomp.stackexchange.com/questions/83/is-there-a-high-quality-nonlinear-programming-solver-for-python\n",
    "    https://www.researchgate.net/post/Solvers_for_mixed-integer_nonlinear_programming\n",
    "    CONOPT implements a GeneralizedReduced Gradient (GRG) method, while IPOPT, Knitro, and Mosek use an interior-point method, and SNOPT uses a sequential quadratic programming (SQP) approach\n",
    "\n",
    "##### 4.6 Bonmin (local solver)\n",
    "     The functions should be twice continuously differentiable The default solvers for MILP and NLP are, respectively, the COIN-OR codes Cbc and Ipopt.\n",
    "###### 4.6.1 NLP\n",
    "    bonmin.nlp_solver -- Choice of the solver for local optima of continuous NLP's\n",
    "######  4.6.2 MILP        \n",
    "    bonmin.milp_solver -- Choose the subsolver to solve MILP sub-problems in OA decompositions.\n",
    "##### 4.7 Couenne (global solver)\n",
    "    The default solvers for MILP and NLP are, respectively, CPLEX12.8 and Ipopt3.12.\n",
    "##### 4.8 Academy license:         \n",
    "    Gurobi(MILP,MIQP): academy free and renewable annually;     \n",
    "    Knitro(NLP): 1 month for academy\n",
    "    LINDO Globale (MINLP): 6 month renewable\n",
    "    AIMMS(platform):6 month renewable\n",
    "    YALMIP, Tomlab for matlab\n",
    "### 5. Available solver Summary\n",
    "    ipopt(/asl, NLP), bonmin(asl, local), couenne(asl, global), BARON, scip, \n",
    "### 6. Questions\n",
    "#### 6.1 Pyomo\n",
    "##### 6.6.1 Suffix\n",
    "    solver_io: multiple interfaces for some solvers --- nl: ASL interface; direct(python): python api; None(shell): gms;\n",
    "### 7. Running speed\n",
    "    Ipopt(20s); cplex(15s);bonmin(41s);gurobi(45s)\n",
    "### n. TODO:\n",
    "1. make bonmin and couenne work (tuning parameters); \n",
    "2. other two solver: scip, BARON; \n",
    "3. usage of neos server; (partly done, not all solvers can be used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCHP design and control problem via optimization\n",
    "### Before construction\n",
    "#### Design\n",
    "    For design stage, control signal should be also simulated for accurate design. In that case, the system capacity should be optimized based on nearly true demand, weather information, energy source prices. Thus, three steps are considered here for accurate demands:\n",
    "    1. TMY3 and single building model can be candidate for designing capacities of different components. (accurate for single building)\n",
    "    1.5 Further, more accurate method of demand prediction can be used, such as machine learnning;\n",
    "    2. but ML requires real data, which can be replaced by more building types, location and weather (generalize for all kinds of building and location) etc simulation data, then use ML\n",
    "    3. Finally, real time test data to build a database and any builidng demands can be predicted accurately via ML.\n",
    "    Overall, ML is used for prediction\n",
    "->>>> Decide: capacities of all kinds of devices; \n",
    "\n",
    "-%%%% Unsolved: whether the weather data should be consided for decive performance;\n",
    "\n",
    "#### Planning\n",
    "    For planning stage, the system will be planned based on designed capacities. Information requred: demand, weather, market. These information can be modelled and uncertainty provided.\n",
    "    \n",
    "#### Design and planning combination\n",
    "    Provide capacity as well as partial load information at same time.\n",
    "    \n",
    "### After construction\n",
    "#### Control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pyomo Solvers and Solver Managers\n",
      "---------------------------------\n",
      "Pyomo uses 'solver managers' to execute 'solvers' that perform\n",
      "optimization and other forms of model analysis.  A solver directly\n",
      "executes an optimizer, typically using an executable found on the\n",
      "user's PATH environment.  Solver managers support a flexible mechanism\n",
      "for asyncronously executing solvers either locally or remotely.  The\n",
      "following solver managers are available in Pyomo:\n",
      "\n",
      "    neos       Asynchronously execute solvers on the NEOS server\n",
      "    phpyro     Specialized PH solver manager that uses pyro\n",
      "    pyro       Execute solvers remotely using pyro\n",
      "    serial     Synchronously execute solvers locally\n",
      "\n",
      "If no solver manager is specified, Pyomo uses the serial solver\n",
      "manager to execute solvers locally.  The pyro and phpyro solver\n",
      "managers require the installation and configuration of the pyro\n",
      "software.  The neos solver manager is used to execute solvers on the\n",
      "NEOS optimization server.\n",
      "\n",
      "\n",
      "Serial Solver Interfaces\n",
      "------------------------\n",
      "The serial, pyro and phpyro solver managers support the following\n",
      "solver interfaces:\n",
      "\n",
      "    asl                  + Interface for solvers using the AMPL Solver\n",
      "                           Library\n",
      "    baron                * The BARON MINLP solver\n",
      "    bilevel_blp_global   + Global solver for continuous bilevel linear\n",
      "                           problems\n",
      "    bilevel_blp_local    + Local solver for continuous bilevel linear\n",
      "                           problems\n",
      "    bilevel_bqp          + Global solver for bilevel quadratic\n",
      "                           problems\n",
      "    bilevel_ld           + Solver for bilevel problems using linear\n",
      "                           duality\n",
      "    cbc                    The CBC LP/MIP solver\n",
      "    conopt                 The CONOPT NLP solver\n",
      "    contrib.gjh            Interface to the AMPL GJH \"solver\"\n",
      "    cplex                * The CPLEX LP/MIP solver\n",
      "    cplex_direct           Direct python interface to CPLEX\n",
      "    cplex_persistent       Persistent python interface to CPLEX\n",
      "    gams                 * The GAMS modeling language\n",
      "    gdpbb                * Branch and Bound based GDP Solver\n",
      "    gdpopt               * The GDPopt decomposition-based Generalized\n",
      "                           Disjunctive Programming (GDP) solver\n",
      "    glpk                 * The GLPK LP/MIP solver\n",
      "    gurobi               * The GUROBI LP/MIP solver\n",
      "    gurobi_direct          Direct python interface to Gurobi\n",
      "    gurobi_persistent      Persistent python interface to Gurobi\n",
      "    ipopt                * The Ipopt NLP solver\n",
      "    mindtpy              * MindtPy: Mixed-Integer Nonlinear\n",
      "                           Decomposition Toolbox in Pyomo\n",
      "    mosek                  Direct python interface to Mosek\n",
      "    mpec_minlp           + MPEC solver transforms to a MINLP\n",
      "    mpec_nlp             + MPEC solver that optimizes a nonlinear\n",
      "                           transformation\n",
      "    multistart           * MultiStart solver for NLPs\n",
      "    path                   Nonlinear MCP solver\n",
      "    pico                   The PICO LP/MIP solver\n",
      "    ps                   * Pyomo's simple pattern search optimizer\n",
      "    py                   + Direct python solver interfaces\n",
      "    scip                   The SCIP LP/MIP solver\n",
      "    trustregion          * Trust region filter method for black\n",
      "                           box/glass box optimization\n",
      "    xpress                 The XPRESS LP/MIP solver\n",
      "\n",
      "An asterisk indicates solvers that are currently available to be run\n",
      "from Pyomo with the serial solver manager. A plus indicates meta-\n",
      "solvers, that are always available.\n",
      "\n",
      "Pyomo also supports solver interfaces that are wrappers around third-\n",
      "party solver interfaces. These interfaces require a subsolver\n",
      "specification that indicates the solver being executed.  For example,\n",
      "the following indicates that the ipopt solver will be used:\n",
      "\n",
      "   asl:ipopt\n",
      "\n",
      "The asl interface provides a generic wrapper for all solvers that use\n",
      "the AMPL Solver Library.\n",
      "\n",
      "Note that subsolvers can not be enumerated automatically for these\n",
      "interfaces.  However, if a solver is specified that is not found,\n",
      "Pyomo assumes that the asl solver interface is being used.  Thus the\n",
      "following solver name will launch ipopt if the 'ipopt' executable is\n",
      "on the user's path:\n",
      "\n",
      "   ipopt\n",
      "\n",
      "\n",
      "NEOS Solver Interfaces\n",
      "----------------------\n",
      "The neos solver manager supports solver interfaces that can be\n",
      "executed remotely on the NEOS optimization server.  The following\n",
      "solver interfaces are available with your current system\n",
      "configuration:\n",
      "\n",
      "    bonmin       Heuristic MINLP solver\n",
      "    cbc          MILP solver\n",
      "    conopt       Feasible path NLP solver\n",
      "    couenne      Exact MINLP solver\n",
      "    cplex        MILP solver\n",
      "    filmint      Heuristic MINLP solver\n",
      "    filter       SQP NLP solver\n",
      "    ipopt        Interior point NLP solver\n",
      "    knitro       Convex MINLP solver\n",
      "    l-bfgs-b     Bound-constrained NLP solver\n",
      "    loqo         Interior point NLP solver\n",
      "    minlp        Heuristic MINLP solver\n",
      "    minos        SLC NLP solver\n",
      "    minto        MILP solver\n",
      "    mosek        Interior point NLP solver\n",
      "    ooqp         Convex QP solver\n",
      "    path         Nonlinear MCP solver\n",
      "    snopt        SQP NLP solver\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pyomo help -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Output ###\n",
      "\n",
      "print_level                            0 <= (          5) <= 12        \n",
      "   Output verbosity level.\n",
      "     Sets the default verbosity level for console output. The larger this\n",
      "     value the more detailed is the output.\n",
      "\n",
      "output_file                   (\"\")\n",
      "   File name of desired output file (leave unset for no file output).\n",
      "     NOTE: This option only works when read from the ipopt.opt options file!\n",
      "     An output file with this name will be written (leave unset for no file\n",
      "     output).  The verbosity level is by default set to \"print_level\", but can\n",
      "     be overridden with \"file_print_level\".  The file name is changed to use\n",
      "     only small letters.\n",
      "   Possible values:\n",
      "    - *                       [Any acceptable standard file name]\n",
      "\n",
      "file_print_level                       0 <= (          5) <= 12        \n",
      "   Verbosity level for output file.\n",
      "     NOTE: This option only works when read from the ipopt.opt options file!\n",
      "     Determines the verbosity level for the file specified by \"output_file\". \n",
      "     By default it is the same as \"print_level\".\n",
      "\n",
      "print_user_options            (\"no\")\n",
      "   Print all options set by the user.\n",
      "     If selected, the algorithm will print the list of all options set by the\n",
      "     user including their values and whether they have been used.  In some\n",
      "     cases this information might be incorrect, due to the internal program\n",
      "     flow.\n",
      "   Possible values:\n",
      "    - no                      [don't print options]\n",
      "    - yes                     [print options]\n",
      "\n",
      "print_options_documentation   (\"no\")\n",
      "   Switch to print all algorithmic options.\n",
      "     If selected, the algorithm will print the list of all available\n",
      "     algorithmic options with some documentation before solving the\n",
      "     optimization problem.\n",
      "   Possible values:\n",
      "    - no                      [don't print list]\n",
      "    - yes                     [print list]\n",
      "\n",
      "print_timing_statistics       (\"no\")\n",
      "   Switch to print timing statistics.\n",
      "     If selected, the program will print the CPU usage (user time) for\n",
      "     selected tasks.\n",
      "   Possible values:\n",
      "    - no                      [don't print statistics]\n",
      "    - yes                     [print all timing statistics]\n",
      "\n",
      "option_file_name              (\"\")\n",
      "   File name of options file (to overwrite default).\n",
      "     By default, the name of the Ipopt options file is \"ipopt.opt\" - or\n",
      "     something else if specified in the IpoptApplication::Initialize call. If\n",
      "     this option is set by SetStringValue BEFORE the options file is read, it\n",
      "     specifies the name of the options file.  It does not make any sense to\n",
      "     specify this option within the options file.\n",
      "   Possible values:\n",
      "    - *                       [Any acceptable standard file name]\n",
      "\n",
      "replace_bounds                (\"no\")\n",
      "   Indicates if all variable bounds should be replaced by inequality\n",
      "   constraints\n",
      "     This option must be set for the inexact algorithm\n",
      "   Possible values:\n",
      "    - no                      [leave bounds on variables]\n",
      "    - yes                     [replace variable bounds by inequality\n",
      "                               constraints]\n",
      "\n",
      "skip_finalize_solution_call   (\"no\")\n",
      "   Indicates if call to NLP::FinalizeSolution after optimization should be\n",
      "   suppressed\n",
      "     In some Ipopt applications, the user might want to call the\n",
      "     FinalizeSolution method separately.  Setting this option to \"yes\" will\n",
      "     cause the IpoptApplication object to suppress the default call to that\n",
      "     method.\n",
      "   Possible values:\n",
      "    - no                      [call FinalizeSolution]\n",
      "    - yes                     [do not call FinalizeSolution]\n",
      "\n",
      "print_info_string             (\"no\")\n",
      "   Enables printing of additional info string at end of iteration output.\n",
      "     This string contains some insider information about the current\n",
      "     iteration.  For details, look for \"Diagnostic Tags\" in the Ipopt\n",
      "     documentation.\n",
      "   Possible values:\n",
      "    - no                      [don't print string]\n",
      "    - yes                     [print string at end of each iteration output]\n",
      "\n",
      "inf_pr_output                 (\"original\")\n",
      "   Determines what value is printed in the \"inf_pr\" output column.\n",
      "     Ipopt works with a reformulation of the original problem, where slacks\n",
      "     are introduced and the problem might have been scaled.  The choice\n",
      "     \"internal\" prints out the constraint violation of this formulation. With\n",
      "     \"original\" the true constraint violation in the original NLP is printed.\n",
      "   Possible values:\n",
      "    - internal                [max-norm of violation of internal equality\n",
      "                               constraints]\n",
      "    - original                [maximal constraint violation in original NLP]\n",
      "\n",
      "print_frequency_iter                   1 <= (          1) <  +inf      \n",
      "   Determines at which iteration frequency the summarizing iteration output\n",
      "   line should be printed.\n",
      "     Summarizing iteration output is printed every print_frequency_iter\n",
      "     iterations, if at least print_frequency_time seconds have passed since\n",
      "     last output.\n",
      "\n",
      "print_frequency_time                   0 <= (          0) <  +inf      \n",
      "   Determines at which time frequency the summarizing iteration output line\n",
      "   should be printed.\n",
      "     Summarizing iteration output is printed if at least print_frequency_time\n",
      "     seconds have passed since last output and the iteration number is a\n",
      "     multiple of print_frequency_iter.\n",
      "\n",
      "\n",
      "\n",
      "### Convergence ###\n",
      "\n",
      "tol                                    0 <  (     1e-008) <  +inf      \n",
      "   Desired convergence tolerance (relative).\n",
      "     Determines the convergence tolerance for the algorithm.  The algorithm\n",
      "     terminates successfully, if the (scaled) NLP error becomes smaller than\n",
      "     this value, and if the (absolute) criteria according to \"dual_inf_tol\",\n",
      "     \"primal_inf_tol\", and \"compl_inf_tol\" are met.  (This is epsilon_tol in\n",
      "     Eqn. (6) in implementation paper).  See also \"acceptable_tol\" as a second\n",
      "     termination criterion.  Note, some other algorithmic features also use\n",
      "     this quantity to determine thresholds etc.\n",
      "\n",
      "s_max                                  0 <  (        100) <  +inf      \n",
      "   Scaling threshold for the NLP error.\n",
      "     (See paragraph after Eqn. (6) in the implementation paper.)\n",
      "\n",
      "max_iter                               0 <= (       3000) <  +inf      \n",
      "   Maximum number of iterations.\n",
      "     The algorithm terminates with an error message if the number of\n",
      "     iterations exceeded this number.\n",
      "\n",
      "max_cpu_time                           0 <  (     1e+006) <  +inf      \n",
      "   Maximum number of CPU seconds.\n",
      "     A limit on CPU seconds that Ipopt can use to solve one problem.  If\n",
      "     during the convergence check this limit is exceeded, Ipopt will terminate\n",
      "     with a corresponding error message.\n",
      "\n",
      "dual_inf_tol                           0 <  (          1) <  +inf      \n",
      "   Desired threshold for the dual infeasibility.\n",
      "     Absolute tolerance on the dual infeasibility. Successful termination\n",
      "     requires that the max-norm of the (unscaled) dual infeasibility is less\n",
      "     than this threshold.\n",
      "\n",
      "constr_viol_tol                        0 <  (     0.0001) <  +inf      \n",
      "   Desired threshold for the constraint violation.\n",
      "     Absolute tolerance on the constraint violation. Successful termination\n",
      "     requires that the max-norm of the (unscaled) constraint violation is less\n",
      "     than this threshold.\n",
      "\n",
      "compl_inf_tol                          0 <  (     0.0001) <  +inf      \n",
      "   Desired threshold for the complementarity conditions.\n",
      "     Absolute tolerance on the complementarity. Successful termination\n",
      "     requires that the max-norm of the (unscaled) complementarity is less than\n",
      "     this threshold.\n",
      "\n",
      "acceptable_tol                         0 <  (     1e-006) <  +inf      \n",
      "   \"Acceptable\" convergence tolerance (relative).\n",
      "     Determines which (scaled) overall optimality error is considered to be\n",
      "     \"acceptable.\" There are two levels of termination criteria.  If the usual\n",
      "     \"desired\" tolerances (see tol, dual_inf_tol etc) are satisfied at an\n",
      "     iteration, the algorithm immediately terminates with a success message. \n",
      "     On the other hand, if the algorithm encounters \"acceptable_iter\" many\n",
      "     iterations in a row that are considered \"acceptable\", it will terminate\n",
      "     before the desired convergence tolerance is met. This is useful in cases\n",
      "     where the algorithm might not be able to achieve the \"desired\" level of\n",
      "     accuracy.\n",
      "\n",
      "acceptable_iter                        0 <= (         15) <  +inf      \n",
      "   Number of \"acceptable\" iterates before triggering termination.\n",
      "     If the algorithm encounters this many successive \"acceptable\" iterates\n",
      "     (see \"acceptable_tol\"), it terminates, assuming that the problem has been\n",
      "     solved to best possible accuracy given round-off.  If it is set to zero,\n",
      "     this heuristic is disabled.\n",
      "\n",
      "acceptable_dual_inf_tol                0 <  (     1e+010) <  +inf      \n",
      "   \"Acceptance\" threshold for the dual infeasibility.\n",
      "     Absolute tolerance on the dual infeasibility. \"Acceptable\" termination\n",
      "     requires that the (max-norm of the unscaled) dual infeasibility is less\n",
      "     than this threshold; see also acceptable_tol.\n",
      "\n",
      "acceptable_constr_viol_tol             0 <  (       0.01) <  +inf      \n",
      "   \"Acceptance\" threshold for the constraint violation.\n",
      "     Absolute tolerance on the constraint violation. \"Acceptable\" termination\n",
      "     requires that the max-norm of the (unscaled) constraint violation is less\n",
      "     than this threshold; see also acceptable_tol.\n",
      "\n",
      "acceptable_compl_inf_tol               0 <  (       0.01) <  +inf      \n",
      "   \"Acceptance\" threshold for the complementarity conditions.\n",
      "     Absolute tolerance on the complementarity. \"Acceptable\" termination\n",
      "     requires that the max-norm of the (unscaled) complementarity is less than\n",
      "     this threshold; see also acceptable_tol.\n",
      "\n",
      "acceptable_obj_change_tol              0 <= (     1e+020) <  +inf      \n",
      "   \"Acceptance\" stopping criterion based on objective function change.\n",
      "     If the relative change of the objective function (scaled by\n",
      "     Max(1,|f(x)|)) is less than this value, this part of the acceptable\n",
      "     tolerance termination is satisfied; see also acceptable_tol.  This is\n",
      "     useful for the quasi-Newton option, which has trouble to bring down the\n",
      "     dual infeasibility.\n",
      "\n",
      "diverging_iterates_tol                 0 <  (     1e+020) <  +inf      \n",
      "   Threshold for maximal value of primal iterates.\n",
      "     If any component of the primal iterates exceeded this value (in absolute\n",
      "     terms), the optimization is aborted with the exit message that the\n",
      "     iterates seem to be diverging.\n",
      "\n",
      "mu_target                              0 <= (          0) <  +inf      \n",
      "   Desired value of complementarity.\n",
      "     Usually, the barrier parameter is driven to zero and the termination test\n",
      "     for complementarity is measured with respect to zero complementarity. \n",
      "     However, in some cases it might be desired to have Ipopt solve barrier\n",
      "     problem for strictly positive value of the barrier parameter.  In this\n",
      "     case, the value of \"mu_target\" specifies the final value of the barrier\n",
      "     parameter, and the termination tests are then defined with respect to the\n",
      "     barrier problem for this value of the barrier parameter.\n",
      "\n",
      "\n",
      "\n",
      "### NLP Scaling ###\n",
      "\n",
      "nlp_scaling_method            (\"gradient-based\")\n",
      "   Select the technique used for scaling the NLP.\n",
      "     Selects the technique used for scaling the problem internally before it\n",
      "     is solved. For user-scaling, the parameters come from the NLP. If you are\n",
      "     using AMPL, they can be specified through suffixes (\"scaling_factor\")\n",
      "   Possible values:\n",
      "    - none                    [no problem scaling will be performed]\n",
      "    - user-scaling            [scaling parameters will come from the user]\n",
      "    - gradient-based          [scale the problem so the maximum gradient at\n",
      "                               the starting point is scaling_max_gradient]\n",
      "    - equilibration-based     [scale the problem so that first derivatives are\n",
      "                               of order 1 at random points (only available\n",
      "                               with MC19)]\n",
      "\n",
      "obj_scaling_factor                  -inf <  (          1) <  +inf      \n",
      "   Scaling factor for the objective function.\n",
      "     This option sets a scaling factor for the objective function. The scaling\n",
      "     is seen internally by Ipopt but the unscaled objective is reported in the\n",
      "     console output. If additional scaling parameters are computed (e.g.\n",
      "     user-scaling or gradient-based), both factors are multiplied. If this\n",
      "     value is chosen to be negative, Ipopt will maximize the objective\n",
      "     function instead of minimizing it.\n",
      "\n",
      "nlp_scaling_max_gradient               0 <  (        100) <  +inf      \n",
      "   Maximum gradient after NLP scaling.\n",
      "     This is the gradient scaling cut-off. If the maximum gradient is above\n",
      "     this value, then gradient based scaling will be performed. Scaling\n",
      "     parameters are calculated to scale the maximum gradient back to this\n",
      "     value. (This is g_max in Section 3.8 of the implementation paper.) Note:\n",
      "     This option is only used if \"nlp_scaling_method\" is chosen as\n",
      "     \"gradient-based\".\n",
      "\n",
      "nlp_scaling_obj_target_gradient         0 <= (          0) <  +inf      \n",
      "   Target value for objective function gradient size.\n",
      "     If a positive number is chosen, the scaling factor the objective function\n",
      "     is computed so that the gradient has the max norm of the given size at\n",
      "     the starting point.  This overrides nlp_scaling_max_gradient for the\n",
      "     objective function.\n",
      "\n",
      "nlp_scaling_constr_target_gradient         0 <= (          0) <  +inf      \n",
      "   Target value for constraint function gradient size.\n",
      "     If a positive number is chosen, the scaling factor the constraint\n",
      "     functions is computed so that the gradient has the max norm of the given\n",
      "     size at the starting point.  This overrides nlp_scaling_max_gradient for\n",
      "     the constraint functions.\n",
      "\n",
      "nlp_scaling_min_value                  0 <= (     1e-008) <  +inf      \n",
      "   Minimum value of gradient-based scaling values.\n",
      "     This is the lower bound for the scaling factors computed by\n",
      "     gradient-based scaling method.  If some derivatives of some functions are\n",
      "     huge, the scaling factors will otherwise become very small, and the\n",
      "     (unscaled) final constraint violation, for example, might then be\n",
      "     significant.  Note: This option is only used if \"nlp_scaling_method\" is\n",
      "     chosen as \"gradient-based\".\n",
      "\n",
      "\n",
      "\n",
      "### NLP ###\n",
      "\n",
      "nlp_lower_bound_inf                 -inf <  (    -1e+019) <  +inf      \n",
      "   any bound less or equal this value will be considered -inf (i.e. not lower\n",
      "   bounded).\n",
      "\n",
      "nlp_upper_bound_inf                 -inf <  (     1e+019) <  +inf      \n",
      "   any bound greater or this value will be considered +inf (i.e. not upper\n",
      "   bounded).\n",
      "\n",
      "fixed_variable_treatment      (\"make_parameter\")\n",
      "   Determines how fixed variables should be handled.\n",
      "     The main difference between those options is that the starting point in\n",
      "     the \"make_constraint\" case still has the fixed variables at their given\n",
      "     values, whereas in the case \"make_parameter\" the functions are always\n",
      "     evaluated with the fixed values for those variables.  Also, for\n",
      "     \"relax_bounds\", the fixing bound constraints are relaxed (according to\"\n",
      "     bound_relax_factor\"). For both \"make_constraints\" and \"relax_bounds\",\n",
      "     bound multipliers are computed for the fixed variables.\n",
      "   Possible values:\n",
      "    - make_parameter          [Remove fixed variable from optimization\n",
      "                               variables]\n",
      "    - make_constraint         [Add equality constraints fixing variables]\n",
      "    - relax_bounds            [Relax fixing bound constraints]\n",
      "\n",
      "dependency_detector           (\"none\")\n",
      "   Indicates which linear solver should be used to detect linearly dependent\n",
      "   equality constraints.\n",
      "     The default and available choices depend on how Ipopt has been compiled. \n",
      "     This is experimental and does not work well.\n",
      "   Possible values:\n",
      "    - none                    [don't check; no extra work at beginning]\n",
      "    - mumps                   [use MUMPS]\n",
      "    - wsmp                    [use WSMP]\n",
      "    - ma28                    [use MA28]\n",
      "\n",
      "dependency_detection_with_rhs (\"no\")\n",
      "   Indicates if the right hand sides of the constraints should be considered\n",
      "   during dependency detection\n",
      "   Possible values:\n",
      "    - no                      [only look at gradients]\n",
      "    - yes                     [also consider right hand side]\n",
      "\n",
      "num_linear_variables                   0 <= (          0) <  +inf      \n",
      "   Number of linear variables\n",
      "     When the Hessian is approximated, it is assumed that the first\n",
      "     num_linear_variables variables are linear.  The Hessian is then not\n",
      "     approximated in this space.  If the get_number_of_nonlinear_variables\n",
      "     method in the TNLP is implemented, this option is ignored.\n",
      "\n",
      "kappa_d                                0 <= (     1e-005) <  +inf      \n",
      "   Weight for linear damping term (to handle one-sided bounds).\n",
      "     (see Section 3.7 in implementation paper.)\n",
      "\n",
      "bound_relax_factor                     0 <= (     1e-008) <  +inf      \n",
      "   Factor for initial relaxation of the bounds.\n",
      "     Before start of the optimization, the bounds given by the user are\n",
      "     relaxed.  This option sets the factor for this relaxation.  If it is set\n",
      "     to zero, then then bounds relaxation is disabled. (See Eqn.(35) in\n",
      "     implementation paper.)\n",
      "\n",
      "honor_original_bounds         (\"yes\")\n",
      "   Indicates whether final points should be projected into original bounds.\n",
      "     Ipopt might relax the bounds during the optimization (see, e.g., option\n",
      "     \"bound_relax_factor\").  This option determines whether the final point\n",
      "     should be projected back into the user-provide original bounds after the\n",
      "     optimization.\n",
      "   Possible values:\n",
      "    - no                      [Leave final point unchanged]\n",
      "    - yes                     [Project final point back into original bounds]\n",
      "\n",
      "check_derivatives_for_naninf  (\"no\")\n",
      "   Indicates whether it is desired to check for Nan/Inf in derivative matrices\n",
      "     Activating this option will cause an error if an invalid number is\n",
      "     detected in the constraint Jacobians or the Lagrangian Hessian.  If this\n",
      "     is not activated, the test is skipped, and the algorithm might proceed\n",
      "     with invalid numbers and fail.  If test is activated and an invalid\n",
      "     number is detected, the matrix is written to output with print_level\n",
      "     corresponding to J_MORE_DETAILED; so beware of large output!\n",
      "   Possible values:\n",
      "    - no                      [Don't check (faster).]\n",
      "    - yes                     [Check Jacobians and Hessian for Nan and Inf.]\n",
      "\n",
      "jac_c_constant                (\"no\")\n",
      "   Indicates whether all equality constraints are linear\n",
      "     Activating this option will cause Ipopt to ask for the Jacobian of the\n",
      "     equality constraints only once from the NLP and reuse this information\n",
      "     later.\n",
      "   Possible values:\n",
      "    - no                      [Don't assume that all equality constraints are\n",
      "                               linear]\n",
      "    - yes                     [Assume that equality constraints Jacobian are\n",
      "                               constant]\n",
      "\n",
      "jac_d_constant                (\"no\")\n",
      "   Indicates whether all inequality constraints are linear\n",
      "     Activating this option will cause Ipopt to ask for the Jacobian of the\n",
      "     inequality constraints only once from the NLP and reuse this information\n",
      "     later.\n",
      "   Possible values:\n",
      "    - no                      [Don't assume that all inequality constraints\n",
      "                               are linear]\n",
      "    - yes                     [Assume that equality constraints Jacobian are\n",
      "                               constant]\n",
      "\n",
      "hessian_constant              (\"no\")\n",
      "   Indicates whether the problem is a quadratic problem\n",
      "     Activating this option will cause Ipopt to ask for the Hessian of the\n",
      "     Lagrangian function only once from the NLP and reuse this information\n",
      "     later.\n",
      "   Possible values:\n",
      "    - no                      [Assume that Hessian changes]\n",
      "    - yes                     [Assume that Hessian is constant]\n",
      "\n",
      "\n",
      "\n",
      "### Initialization ###\n",
      "\n",
      "bound_push                             0 <  (       0.01) <  +inf      \n",
      "   Desired minimum absolute distance from the initial point to bound.\n",
      "     Determines how much the initial point might have to be modified in order\n",
      "     to be sufficiently inside the bounds (together with \"bound_frac\").  (This\n",
      "     is kappa_1 in Section 3.6 of implementation paper.)\n",
      "\n",
      "bound_frac                             0 <  (       0.01) <= 0.5       \n",
      "   Desired minimum relative distance from the initial point to bound.\n",
      "     Determines how much the initial point might have to be modified in order\n",
      "     to be sufficiently inside the bounds (together with \"bound_push\").  (This\n",
      "     is kappa_2 in Section 3.6 of implementation paper.)\n",
      "\n",
      "slack_bound_push                       0 <  (       0.01) <  +inf      \n",
      "   Desired minimum absolute distance from the initial slack to bound.\n",
      "     Determines how much the initial slack variables might have to be modified\n",
      "     in order to be sufficiently inside the inequality bounds (together with\n",
      "     \"slack_bound_frac\").  (This is kappa_1 in Section 3.6 of implementation\n",
      "     paper.)\n",
      "\n",
      "slack_bound_frac                       0 <  (       0.01) <= 0.5       \n",
      "   Desired minimum relative distance from the initial slack to bound.\n",
      "     Determines how much the initial slack variables might have to be modified\n",
      "     in order to be sufficiently inside the inequality bounds (together with\n",
      "     \"slack_bound_push\").  (This is kappa_2 in Section 3.6 of implementation\n",
      "     paper.)\n",
      "\n",
      "constr_mult_init_max                   0 <= (       1000) <  +inf      \n",
      "   Maximum allowed least-square guess of constraint multipliers.\n",
      "     Determines how large the initial least-square guesses of the constraint\n",
      "     multipliers are allowed to be (in max-norm). If the guess is larger than\n",
      "     this value, it is discarded and all constraint multipliers are set to\n",
      "     zero.  This options is also used when initializing the restoration phase.\n",
      "     By default, \"resto.constr_mult_init_max\" (the one used in\n",
      "     RestoIterateInitializer) is set to zero.\n",
      "\n",
      "bound_mult_init_val                    0 <  (          1) <  +inf      \n",
      "   Initial value for the bound multipliers.\n",
      "     All dual variables corresponding to bound constraints are initialized to\n",
      "     this value.\n",
      "\n",
      "bound_mult_init_method        (\"constant\")\n",
      "   Initialization method for bound multipliers\n",
      "     This option defines how the iterates for the bound multipliers are\n",
      "     initialized.  If \"constant\" is chosen, then all bound multipliers are\n",
      "     initialized to the value of \"bound_mult_init_val\".  If \"mu-based\" is\n",
      "     chosen, the each value is initialized to the the value of \"mu_init\"\n",
      "     divided by the corresponding slack variable.  This latter option might be\n",
      "     useful if the starting point is close to the optimal solution.\n",
      "   Possible values:\n",
      "    - constant                [set all bound multipliers to the value of\n",
      "                               bound_mult_init_val]\n",
      "    - mu-based                [initialize to mu_init/x_slack]\n",
      "\n",
      "least_square_init_primal      (\"no\")\n",
      "   Least square initialization of the primal variables\n",
      "     If set to yes, Ipopt ignores the user provided point and solves a least\n",
      "     square problem for the primal variables (x and s), to fit the linearized\n",
      "     equality and inequality constraints.  This might be useful if the user\n",
      "     doesn't know anything about the starting point, or for solving an LP or\n",
      "     QP.\n",
      "   Possible values:\n",
      "    - no                      [take user-provided point]\n",
      "    - yes                     [overwrite user-provided point with least-square\n",
      "                               estimates]\n",
      "\n",
      "least_square_init_duals       (\"no\")\n",
      "   Least square initialization of all dual variables\n",
      "     If set to yes, Ipopt tries to compute least-square multipliers\n",
      "     (considering ALL dual variables).  If successful, the bound multipliers\n",
      "     are possibly corrected to be at least bound_mult_init_val. This might be\n",
      "     useful if the user doesn't know anything about the starting point, or for\n",
      "     solving an LP or QP.  This overwrites option \"bound_mult_init_method\".\n",
      "   Possible values:\n",
      "    - no                      [use bound_mult_init_val and least-square\n",
      "                               equality constraint multipliers]\n",
      "    - yes                     [overwrite user-provided point with least-square\n",
      "                               estimates]\n",
      "\n",
      "\n",
      "\n",
      "### Barrier Parameter Update ###\n",
      "\n",
      "mu_max_fact                            0 <  (       1000) <  +inf      \n",
      "   Factor for initialization of maximum value for barrier parameter.\n",
      "     This option determines the upper bound on the barrier parameter.  This\n",
      "     upper bound is computed as the average complementarity at the initial\n",
      "     point times the value of this option. (Only used if option \"mu_strategy\"\n",
      "     is chosen as \"adaptive\".)\n",
      "\n",
      "mu_max                                 0 <  (     100000) <  +inf      \n",
      "   Maximum value for barrier parameter.\n",
      "     This option specifies an upper bound on the barrier parameter in the\n",
      "     adaptive mu selection mode.  If this option is set, it overwrites the\n",
      "     effect of mu_max_fact. (Only used if option \"mu_strategy\" is chosen as\n",
      "     \"adaptive\".)\n",
      "\n",
      "mu_min                                 0 <  (     1e-011) <  +inf      \n",
      "   Minimum value for barrier parameter.\n",
      "     This option specifies the lower bound on the barrier parameter in the\n",
      "     adaptive mu selection mode. By default, it is set to the minimum of 1e-11\n",
      "     and min(\"tol\",\"compl_inf_tol\")/(\"barrier_tol_factor\"+1), which should be\n",
      "     a reasonable value. (Only used if option \"mu_strategy\" is chosen as\n",
      "     \"adaptive\".)\n",
      "\n",
      "adaptive_mu_globalization     (\"obj-constr-filter\")\n",
      "   Globalization strategy for the adaptive mu selection mode.\n",
      "     To achieve global convergence of the adaptive version, the algorithm has\n",
      "     to switch to the monotone mode (Fiacco-McCormick approach) when\n",
      "     convergence does not seem to appear.  This option sets the criterion used\n",
      "     to decide when to do this switch. (Only used if option \"mu_strategy\" is\n",
      "     chosen as \"adaptive\".)\n",
      "   Possible values:\n",
      "    - kkt-error               [nonmonotone decrease of kkt-error]\n",
      "    - obj-constr-filter       [2-dim filter for objective and constraint\n",
      "                               violation]\n",
      "    - never-monotone-mode     [disables globalization]\n",
      "\n",
      "adaptive_mu_kkterror_red_iters         0 <= (          4) <  +inf      \n",
      "   Maximum number of iterations requiring sufficient progress.\n",
      "     For the \"kkt-error\" based globalization strategy, sufficient progress\n",
      "     must be made for \"adaptive_mu_kkterror_red_iters\" iterations. If this\n",
      "     number of iterations is exceeded, the globalization strategy switches to\n",
      "     the monotone mode.\n",
      "\n",
      "adaptive_mu_kkterror_red_fact          0 <  (     0.9999) <  1         \n",
      "   Sufficient decrease factor for \"kkt-error\" globalization strategy.\n",
      "     For the \"kkt-error\" based globalization strategy, the error must decrease\n",
      "     by this factor to be deemed sufficient decrease.\n",
      "\n",
      "filter_margin_fact                     0 <  (     1e-005) <  1         \n",
      "   Factor determining width of margin for obj-constr-filter adaptive\n",
      "   globalization strategy.\n",
      "     When using the adaptive globalization strategy, \"obj-constr-filter\",\n",
      "     sufficient progress for a filter entry is defined as follows: (new obj) <\n",
      "     (filter obj) - filter_margin_fact*(new constr-viol) OR (new constr-viol)\n",
      "     < (filter constr-viol) - filter_margin_fact*(new constr-viol).  For the\n",
      "     description of the \"kkt-error-filter\" option see \"filter_max_margin\".\n",
      "\n",
      "filter_max_margin                      0 <  (          1) <  +inf      \n",
      "   Maximum width of margin in obj-constr-filter adaptive globalization\n",
      "   strategy.\n",
      "\n",
      "adaptive_mu_restore_previous_iterate(\"no\")\n",
      "   Indicates if the previous iterate should be restored if the monotone mode\n",
      "   is entered.\n",
      "     When the globalization strategy for the adaptive barrier algorithm\n",
      "     switches to the monotone mode, it can either start from the most recent\n",
      "     iterate (no), or from the last iterate that was accepted (yes).\n",
      "   Possible values:\n",
      "    - no                      [don't restore accepted iterate]\n",
      "    - yes                     [restore accepted iterate]\n",
      "\n",
      "adaptive_mu_monotone_init_factor         0 <  (        0.8) <  +inf      \n",
      "   Determines the initial value of the barrier parameter when switching to the\n",
      "   monotone mode.\n",
      "     When the globalization strategy for the adaptive barrier algorithm\n",
      "     switches to the monotone mode and fixed_mu_oracle is chosen as\n",
      "     \"average_compl\", the barrier parameter is set to the current average\n",
      "     complementarity times the value of \"adaptive_mu_monotone_init_factor\".\n",
      "\n",
      "adaptive_mu_kkt_norm_type     (\"2-norm-squared\")\n",
      "   Norm used for the KKT error in the adaptive mu globalization strategies.\n",
      "     When computing the KKT error for the globalization strategies, the norm\n",
      "     to be used is specified with this option. Note, this options is also used\n",
      "     in the QualityFunctionMuOracle.\n",
      "   Possible values:\n",
      "    - 1-norm                  [use the 1-norm (abs sum)]\n",
      "    - 2-norm-squared          [use the 2-norm squared (sum of squares)]\n",
      "    - max-norm                [use the infinity norm (max)]\n",
      "    - 2-norm                  [use 2-norm]\n",
      "\n",
      "mu_strategy                   (\"monotone\")\n",
      "   Update strategy for barrier parameter.\n",
      "     Determines which barrier parameter update strategy is to be used.\n",
      "   Possible values:\n",
      "    - monotone                [use the monotone (Fiacco-McCormick) strategy]\n",
      "    - adaptive                [use the adaptive update strategy]\n",
      "\n",
      "mu_oracle                     (\"quality-function\")\n",
      "   Oracle for a new barrier parameter in the adaptive strategy.\n",
      "     Determines how a new barrier parameter is computed in each \"free-mode\"\n",
      "     iteration of the adaptive barrier parameter strategy. (Only considered if\n",
      "     \"adaptive\" is selected for option \"mu_strategy\").\n",
      "   Possible values:\n",
      "    - probing                 [Mehrotra's probing heuristic]\n",
      "    - loqo                    [LOQO's centrality rule]\n",
      "    - quality-function        [minimize a quality function]\n",
      "\n",
      "fixed_mu_oracle               (\"average_compl\")\n",
      "   Oracle for the barrier parameter when switching to fixed mode.\n",
      "     Determines how the first value of the barrier parameter should be\n",
      "     computed when switching to the \"monotone mode\" in the adaptive strategy.\n",
      "     (Only considered if \"adaptive\" is selected for option \"mu_strategy\".)\n",
      "   Possible values:\n",
      "    - probing                 [Mehrotra's probing heuristic]\n",
      "    - loqo                    [LOQO's centrality rule]\n",
      "    - quality-function        [minimize a quality function]\n",
      "    - average_compl           [base on current average complementarity]\n",
      "\n",
      "mu_init                                0 <  (        0.1) <  +inf      \n",
      "   Initial value for the barrier parameter.\n",
      "     This option determines the initial value for the barrier parameter (mu). \n",
      "     It is only relevant in the monotone, Fiacco-McCormick version of the\n",
      "     algorithm. (i.e., if \"mu_strategy\" is chosen as \"monotone\")\n",
      "\n",
      "barrier_tol_factor                     0 <  (         10) <  +inf      \n",
      "   Factor for mu in barrier stop test.\n",
      "     The convergence tolerance for each barrier problem in the monotone mode\n",
      "     is the value of the barrier parameter times \"barrier_tol_factor\". This\n",
      "     option is also used in the adaptive mu strategy during the monotone mode.\n",
      "     (This is kappa_epsilon in implementation paper).\n",
      "\n",
      "mu_linear_decrease_factor              0 <  (        0.2) <  1         \n",
      "   Determines linear decrease rate of barrier parameter.\n",
      "     For the Fiacco-McCormick update procedure the new barrier parameter mu is\n",
      "     obtained by taking the minimum of mu*\"mu_linear_decrease_factor\" and\n",
      "     mu^\"superlinear_decrease_power\".  (This is kappa_mu in implementation\n",
      "     paper.) This option is also used in the adaptive mu strategy during the\n",
      "     monotone mode.\n",
      "\n",
      "mu_superlinear_decrease_power          1 <  (        1.5) <  2         \n",
      "   Determines superlinear decrease rate of barrier parameter.\n",
      "     For the Fiacco-McCormick update procedure the new barrier parameter mu is\n",
      "     obtained by taking the minimum of mu*\"mu_linear_decrease_factor\" and\n",
      "     mu^\"superlinear_decrease_power\".  (This is theta_mu in implementation\n",
      "     paper.) This option is also used in the adaptive mu strategy during the\n",
      "     monotone mode.\n",
      "\n",
      "mu_allow_fast_monotone_decrease(\"yes\")\n",
      "   Allow skipping of barrier problem if barrier test is already met.\n",
      "     If set to \"no\", the algorithm enforces at least one iteration per barrier\n",
      "     problem, even if the barrier test is already met for the updated barrier\n",
      "     parameter.\n",
      "   Possible values:\n",
      "    - no                      [Take at least one iteration per barrier problem]\n",
      "    - yes                     [Allow fast decrease of mu if barrier test it met]\n",
      "\n",
      "tau_min                                0 <  (       0.99) <  1         \n",
      "   Lower bound on fraction-to-the-boundary parameter tau.\n",
      "     (This is tau_min in the implementation paper.)  This option is also used\n",
      "     in the adaptive mu strategy during the monotone mode.\n",
      "\n",
      "sigma_max                              0 <  (        100) <  +inf      \n",
      "   Maximum value of the centering parameter.\n",
      "     This is the upper bound for the centering parameter chosen by the quality\n",
      "     function based barrier parameter update. (Only used if option \"mu_oracle\"\n",
      "     is set to \"quality-function\".)\n",
      "\n",
      "sigma_min                              0 <= (     1e-006) <  +inf      \n",
      "   Minimum value of the centering parameter.\n",
      "     This is the lower bound for the centering parameter chosen by the quality\n",
      "     function based barrier parameter update. (Only used if option \"mu_oracle\"\n",
      "     is set to \"quality-function\".)\n",
      "\n",
      "quality_function_norm_type    (\"2-norm-squared\")\n",
      "   Norm used for components of the quality function.\n",
      "     (Only used if option \"mu_oracle\" is set to \"quality-function\".)\n",
      "   Possible values:\n",
      "    - 1-norm                  [use the 1-norm (abs sum)]\n",
      "    - 2-norm-squared          [use the 2-norm squared (sum of squares)]\n",
      "    - max-norm                [use the infinity norm (max)]\n",
      "    - 2-norm                  [use 2-norm]\n",
      "\n",
      "quality_function_centrality   (\"none\")\n",
      "   The penalty term for centrality that is included in quality function.\n",
      "     This determines whether a term is added to the quality function to\n",
      "     penalize deviation from centrality with respect to complementarity.  The\n",
      "     complementarity measure here is the xi in the Loqo update rule. (Only\n",
      "     used if option \"mu_oracle\" is set to \"quality-function\".)\n",
      "   Possible values:\n",
      "    - none                    [no penalty term is added]\n",
      "    - log                     [complementarity * the log of the centrality\n",
      "                               measure]\n",
      "    - reciprocal              [complementarity * the reciprocal of the\n",
      "                               centrality measure]\n",
      "    - cubed-reciprocal        [complementarity * the reciprocal of the\n",
      "                               centrality measure cubed]\n",
      "\n",
      "quality_function_balancing_term(\"none\")\n",
      "   The balancing term included in the quality function for centrality.\n",
      "     This determines whether a term is added to the quality function that\n",
      "     penalizes situations where the complementarity is much smaller than dual\n",
      "     and primal infeasibilities. (Only used if option \"mu_oracle\" is set to\n",
      "     \"quality-function\".)\n",
      "   Possible values:\n",
      "    - none                    [no balancing term is added]\n",
      "    - cubic                   [Max(0,Max(dual_inf,primal_inf)-compl)^3]\n",
      "\n",
      "quality_function_max_section_steps         0 <= (          8) <  +inf      \n",
      "   Maximum number of search steps during direct search procedure determining\n",
      "   the optimal centering parameter.\n",
      "     The golden section search is performed for the quality function based mu\n",
      "     oracle. (Only used if option \"mu_oracle\" is set to \"quality-function\".)\n",
      "\n",
      "quality_function_section_sigma_tol         0 <= (       0.01) <  1         \n",
      "   Tolerance for the section search procedure determining the optimal\n",
      "   centering parameter (in sigma space).\n",
      "     The golden section search is performed for the quality function based mu\n",
      "     oracle. (Only used if option \"mu_oracle\" is set to \"quality-function\".)\n",
      "\n",
      "quality_function_section_qf_tol         0 <= (          0) <  1         \n",
      "   Tolerance for the golden section search procedure determining the optimal\n",
      "   centering parameter (in the function value space).\n",
      "     The golden section search is performed for the quality function based mu\n",
      "     oracle. (Only used if option \"mu_oracle\" is set to \"quality-function\".)\n",
      "\n",
      "\n",
      "\n",
      "### Line Search ###\n",
      "\n",
      "line_search_method            (\"filter\")\n",
      "   Globalization method used in backtracking line search\n",
      "     Only the \"filter\" choice is officially supported.  But sometimes, good\n",
      "     results might be obtained with the other choices.\n",
      "   Possible values:\n",
      "    - filter                  [Filter method]\n",
      "    - cg-penalty              [Chen-Goldfarb penalty function]\n",
      "    - penalty                 [Standard penalty function]\n",
      "\n",
      "alpha_red_factor                       0 <  (        0.5) <  1         \n",
      "   Fractional reduction of the trial step size in the backtracking line search.\n",
      "     At every step of the backtracking line search, the trial step size is\n",
      "     reduced by this factor.\n",
      "\n",
      "accept_every_trial_step       (\"no\")\n",
      "   Always accept the first trial step.\n",
      "     Setting this option to \"yes\" essentially disables the line search and\n",
      "     makes the algorithm take aggressive steps, without global convergence\n",
      "     guarantees.\n",
      "   Possible values:\n",
      "    - no                      [don't arbitrarily accept the full step]\n",
      "    - yes                     [always accept the full step]\n",
      "\n",
      "accept_after_max_steps                -1 <= (         -1) <  +inf      \n",
      "   Accept a trial point after maximal this number of steps.\n",
      "     Even if it does not satisfy line search conditions.\n",
      "\n",
      "alpha_for_y                   (\"primal\")\n",
      "   Method to determine the step size for constraint multipliers.\n",
      "     This option determines how the step size (alpha_y) will be calculated\n",
      "     when updating the constraint multipliers.\n",
      "   Possible values:\n",
      "    - primal                  [use primal step size]\n",
      "    - bound-mult              [use step size for the bound multipliers (good\n",
      "                               for LPs)]\n",
      "    - min                     [use the min of primal and bound multipliers]\n",
      "    - max                     [use the max of primal and bound multipliers]\n",
      "    - full                    [take a full step of size one]\n",
      "    - min-dual-infeas         [choose step size minimizing new dual\n",
      "                               infeasibility]\n",
      "    - safer-min-dual-infeas   [like \"min_dual_infeas\", but safeguarded by\n",
      "                               \"min\" and \"max\"]\n",
      "    - primal-and-full         [use the primal step size, and full step if\n",
      "                               delta_x <= alpha_for_y_tol]\n",
      "    - dual-and-full           [use the dual step size, and full step if\n",
      "                               delta_x <= alpha_for_y_tol]\n",
      "    - acceptor                [Call LSAcceptor to get step size for y]\n",
      "\n",
      "alpha_for_y_tol                        0 <= (         10) <  +inf      \n",
      "   Tolerance for switching to full equality multiplier steps.\n",
      "     This is only relevant if \"alpha_for_y\" is chosen \"primal-and-full\" or\n",
      "     \"dual-and-full\".  The step size for the equality constraint multipliers\n",
      "     is taken to be one if the max-norm of the primal step is less than this\n",
      "     tolerance.\n",
      "\n",
      "tiny_step_tol                          0 <= (2.22045e-015) <  +inf      \n",
      "   Tolerance for detecting numerically insignificant steps.\n",
      "     If the search direction in the primal variables (x and s) is, in relative\n",
      "     terms for each component, less than this value, the algorithm accepts the\n",
      "     full step without line search.  If this happens repeatedly, the algorithm\n",
      "     will terminate with a corresponding exit message. The default value is 10\n",
      "     times machine precision.\n",
      "\n",
      "tiny_step_y_tol                        0 <= (       0.01) <  +inf      \n",
      "   Tolerance for quitting because of numerically insignificant steps.\n",
      "     If the search direction in the primal variables (x and s) is, in relative\n",
      "     terms for each component, repeatedly less than tiny_step_tol, and the\n",
      "     step in the y variables is smaller than this threshold, the algorithm\n",
      "     will terminate.\n",
      "\n",
      "watchdog_shortened_iter_trigger         0 <= (         10) <  +inf      \n",
      "   Number of shortened iterations that trigger the watchdog.\n",
      "     If the number of successive iterations in which the backtracking line\n",
      "     search did not accept the first trial point exceeds this number, the\n",
      "     watchdog procedure is activated.  Choosing \"0\" here disables the watchdog\n",
      "     procedure.\n",
      "\n",
      "watchdog_trial_iter_max                1 <= (          3) <  +inf      \n",
      "   Maximum number of watchdog iterations.\n",
      "     This option determines the number of trial iterations allowed before the\n",
      "     watchdog procedure is aborted and the algorithm returns to the stored\n",
      "     point.\n",
      "\n",
      "theta_max_fact                         0 <  (      10000) <  +inf      \n",
      "   Determines upper bound for constraint violation in the filter.\n",
      "     The algorithmic parameter theta_max is determined as theta_max_fact times\n",
      "     the maximum of 1 and the constraint violation at initial point.  Any\n",
      "     point with a constraint violation larger than theta_max is unacceptable\n",
      "     to the filter (see Eqn. (21) in the implementation paper).\n",
      "\n",
      "theta_min_fact                         0 <  (     0.0001) <  +inf      \n",
      "   Determines constraint violation threshold in the switching rule.\n",
      "     The algorithmic parameter theta_min is determined as theta_min_fact times\n",
      "     the maximum of 1 and the constraint violation at initial point.  The\n",
      "     switching rules treats an iteration as an h-type iteration whenever the\n",
      "     current constraint violation is larger than theta_min (see paragraph\n",
      "     before Eqn. (19) in the implementation paper).\n",
      "\n",
      "eta_phi                                0 <  (     1e-008) <  0.5       \n",
      "   Relaxation factor in the Armijo condition.\n",
      "     (See Eqn. (20) in the implementation paper)\n",
      "\n",
      "delta                                  0 <  (          1) <  +inf      \n",
      "   Multiplier for constraint violation in the switching rule.\n",
      "     (See Eqn. (19) in the implementation paper.)\n",
      "\n",
      "s_phi                                  1 <  (        2.3) <  +inf      \n",
      "   Exponent for linear barrier function model in the switching rule.\n",
      "     (See Eqn. (19) in the implementation paper.)\n",
      "\n",
      "s_theta                                1 <  (        1.1) <  +inf      \n",
      "   Exponent for current constraint violation in the switching rule.\n",
      "     (See Eqn. (19) in the implementation paper.)\n",
      "\n",
      "gamma_phi                              0 <  (     1e-008) <  1         \n",
      "   Relaxation factor in the filter margin for the barrier function.\n",
      "     (See Eqn. (18a) in the implementation paper.)\n",
      "\n",
      "gamma_theta                            0 <  (     1e-005) <  1         \n",
      "   Relaxation factor in the filter margin for the constraint violation.\n",
      "     (See Eqn. (18b) in the implementation paper.)\n",
      "\n",
      "alpha_min_frac                         0 <  (       0.05) <  1         \n",
      "   Safety factor for the minimal step size (before switching to restoration\n",
      "   phase).\n",
      "     (This is gamma_alpha in Eqn. (20) in the implementation paper.)\n",
      "\n",
      "max_soc                                0 <= (          4) <  +inf      \n",
      "   Maximum number of second order correction trial steps at each iteration.\n",
      "     Choosing 0 disables the second order corrections. (This is p^{max} of\n",
      "     Step A-5.9 of Algorithm A in the implementation paper.)\n",
      "\n",
      "kappa_soc                              0 <  (       0.99) <  +inf      \n",
      "   Factor in the sufficient reduction rule for second order correction.\n",
      "     This option determines how much a second order correction step must\n",
      "     reduce the constraint violation so that further correction steps are\n",
      "     attempted.  (See Step A-5.9 of Algorithm A in the implementation paper.)\n",
      "\n",
      "obj_max_inc                            1 <  (          5) <  +inf      \n",
      "   Determines the upper bound on the acceptable increase of barrier objective\n",
      "   function.\n",
      "     Trial points are rejected if they lead to an increase in the barrier\n",
      "     objective function by more than obj_max_inc orders of magnitude.\n",
      "\n",
      "max_filter_resets                      0 <= (          5) <  +inf      \n",
      "   Maximal allowed number of filter resets\n",
      "     A positive number enables a heuristic that resets the filter, whenever in\n",
      "     more than \"filter_reset_trigger\" successive iterations the last rejected\n",
      "     trial steps size was rejected because of the filter.  This option\n",
      "     determine the maximal number of resets that are allowed to take place.\n",
      "\n",
      "filter_reset_trigger                   1 <= (          5) <  +inf      \n",
      "   Number of iterations that trigger the filter reset.\n",
      "     If the filter reset heuristic is active and the number of successive\n",
      "     iterations in which the last rejected trial step size was rejected\n",
      "     because of the filter, the filter is reset.\n",
      "\n",
      "corrector_type                (\"none\")\n",
      "   The type of corrector steps that should be taken (unsupported!).\n",
      "     If \"mu_strategy\" is \"adaptive\", this option determines what kind of\n",
      "     corrector steps should be tried.\n",
      "   Possible values:\n",
      "    - none                    [no corrector]\n",
      "    - affine                  [corrector step towards mu=0]\n",
      "    - primal-dual             [corrector step towards current mu]\n",
      "\n",
      "skip_corr_if_neg_curv         (\"yes\")\n",
      "   Skip the corrector step in negative curvature iteration (unsupported!).\n",
      "     The corrector step is not tried if negative curvature has been\n",
      "     encountered during the computation of the search direction in the current\n",
      "     iteration. This option is only used if \"mu_strategy\" is \"adaptive\".\n",
      "   Possible values:\n",
      "    - no                      [don't skip]\n",
      "    - yes                     [skip]\n",
      "\n",
      "skip_corr_in_monotone_mode    (\"yes\")\n",
      "   Skip the corrector step during monotone barrier parameter mode\n",
      "   (unsupported!).\n",
      "     The corrector step is not tried if the algorithm is currently in the\n",
      "     monotone mode (see also option \"barrier_strategy\").This option is only\n",
      "     used if \"mu_strategy\" is \"adaptive\".\n",
      "   Possible values:\n",
      "    - no                      [don't skip]\n",
      "    - yes                     [skip]\n",
      "\n",
      "corrector_compl_avrg_red_fact          0 <  (          1) <  +inf      \n",
      "   Complementarity tolerance factor for accepting corrector step\n",
      "   (unsupported!).\n",
      "     This option determines the factor by which complementarity is allowed to\n",
      "     increase for a corrector step to be accepted.\n",
      "\n",
      "nu_init                                0 <  (     1e-006) <  +inf      \n",
      "   Initial value of the penalty parameter.\n",
      "\n",
      "nu_inc                                 0 <  (     0.0001) <  +inf      \n",
      "   Increment of the penalty parameter.\n",
      "\n",
      "rho                                    0 <  (        0.1) <  1         \n",
      "   Value in penalty parameter update formula.\n",
      "\n",
      "kappa_sigma                            0 <  (     1e+010) <  +inf      \n",
      "   Factor limiting the deviation of dual variables from primal estimates.\n",
      "     If the dual variables deviate from their primal estimates, a correction\n",
      "     is performed. (See Eqn. (16) in the implementation paper.) Setting the\n",
      "     value to less than 1 disables the correction.\n",
      "\n",
      "recalc_y                      (\"no\")\n",
      "   Tells the algorithm to recalculate the equality and inequality multipliers\n",
      "   as least square estimates.\n",
      "     This asks the algorithm to recompute the multipliers, whenever the\n",
      "     current infeasibility is less than recalc_y_feas_tol. Choosing yes might\n",
      "     be helpful in the quasi-Newton option.  However, each recalculation\n",
      "     requires an extra factorization of the linear system.  If a limited\n",
      "     memory quasi-Newton option is chosen, this is used by default.\n",
      "   Possible values:\n",
      "    - no                      [use the Newton step to update the multipliers]\n",
      "    - yes                     [use least-square multiplier estimates]\n",
      "\n",
      "recalc_y_feas_tol                      0 <  (     1e-006) <  +inf      \n",
      "   Feasibility threshold for recomputation of multipliers.\n",
      "     If recalc_y is chosen and the current infeasibility is less than this\n",
      "     value, then the multipliers are recomputed.\n",
      "\n",
      "slack_move                             0 <= (1.81899e-012) <  +inf      \n",
      "   Correction size for very small slacks.\n",
      "     Due to numerical issues or the lack of an interior, the slack variables\n",
      "     might become very small.  If a slack becomes very small compared to\n",
      "     machine precision, the corresponding bound is moved slightly.  This\n",
      "     parameter determines how large the move should be.  Its default value is\n",
      "     mach_eps^{3/4}.  (See also end of Section 3.5 in implementation paper -\n",
      "     but actual implementation might be somewhat different.)\n",
      "\n",
      "constraint_violation_norm_type(\"1-norm\")\n",
      "   Norm to be used for the constraint violation in the line search.\n",
      "     Determines which norm should be used when the algorithm computes the\n",
      "     constraint violation in the line search.\n",
      "   Possible values:\n",
      "    - 1-norm                  [use the 1-norm]\n",
      "    - 2-norm                  [use the 2-norm]\n",
      "    - max-norm                [use the infinity norm]\n",
      "\n",
      "\n",
      "\n",
      "### Warm Start ###\n",
      "\n",
      "warm_start_init_point         (\"no\")\n",
      "   Warm-start for initial point\n",
      "     Indicates whether this optimization should use a warm start\n",
      "     initialization, where values of primal and dual variables are given\n",
      "     (e.g., from a previous optimization of a related problem.)\n",
      "   Possible values:\n",
      "    - no                      [do not use the warm start initialization]\n",
      "    - yes                     [use the warm start initialization]\n",
      "\n",
      "warm_start_same_structure     (\"no\")\n",
      "   Indicates whether a problem with a structure identical to the previous one\n",
      "   is to be solved.\n",
      "     If \"yes\" is chosen, then the algorithm assumes that an NLP is now to be\n",
      "     solved, whose structure is identical to one that already was considered\n",
      "     (with the same NLP object).\n",
      "   Possible values:\n",
      "    - no                      [Assume this is a new problem.]\n",
      "    - yes                     [Assume this is problem has known structure]\n",
      "\n",
      "warm_start_bound_push                  0 <  (      0.001) <  +inf      \n",
      "   same as bound_push for the regular initializer.\n",
      "\n",
      "warm_start_bound_frac                  0 <  (      0.001) <= 0.5       \n",
      "   same as bound_frac for the regular initializer.\n",
      "\n",
      "warm_start_slack_bound_push            0 <  (      0.001) <  +inf      \n",
      "   same as slack_bound_push for the regular initializer.\n",
      "\n",
      "warm_start_slack_bound_frac            0 <  (      0.001) <= 0.5       \n",
      "   same as slack_bound_frac for the regular initializer.\n",
      "\n",
      "warm_start_mult_bound_push             0 <  (      0.001) <  +inf      \n",
      "   same as mult_bound_push for the regular initializer.\n",
      "\n",
      "warm_start_mult_init_max            -inf <  (     1e+006) <  +inf      \n",
      "   Maximum initial value for the equality multipliers.\n",
      "\n",
      "warm_start_entire_iterate     (\"no\")\n",
      "   Tells algorithm whether to use the GetWarmStartIterate method in the NLP.\n",
      "   Possible values:\n",
      "    - no                      [call GetStartingPoint in the NLP]\n",
      "    - yes                     [call GetWarmStartIterate in the NLP]\n",
      "\n",
      "\n",
      "\n",
      "### Linear Solver ###\n",
      "\n",
      "linear_solver                 (\"mumps\")\n",
      "   Linear solver used for step computations.\n",
      "     Determines which linear algebra package is to be used for the solution of\n",
      "     the augmented linear system (for obtaining the search directions). Note,\n",
      "     the code must have been compiled with the linear solver you want to\n",
      "     choose. Depending on your Ipopt installation, not all options are\n",
      "     available.\n",
      "   Possible values:\n",
      "    - ma27                    [use the Harwell routine MA27]\n",
      "    - ma57                    [use the Harwell routine MA57]\n",
      "    - ma77                    [use the Harwell routine HSL_MA77]\n",
      "    - ma86                    [use the Harwell routine HSL_MA86]\n",
      "    - ma97                    [use the Harwell routine HSL_MA97]\n",
      "    - pardiso                 [use the Pardiso package]\n",
      "    - wsmp                    [use WSMP package]\n",
      "    - mumps                   [use MUMPS package]\n",
      "    - custom                  [use custom linear solver]\n",
      "\n",
      "linear_system_scaling         (\"none\")\n",
      "   Method for scaling the linear system.\n",
      "     Determines the method used to compute symmetric scaling factors for the\n",
      "     augmented system (see also the \"linear_scaling_on_demand\" option).  This\n",
      "     scaling is independent of the NLP problem scaling.  By default, MC19 is\n",
      "     only used if MA27 or MA57 are selected as linear solvers. This value is\n",
      "     only available if Ipopt has been compiled with MC19.\n",
      "   Possible values:\n",
      "    - none                    [no scaling will be performed]\n",
      "    - mc19                    [use the Harwell routine MC19]\n",
      "    - slack-based             [use the slack values]\n",
      "\n",
      "linear_scaling_on_demand      (\"yes\")\n",
      "   Flag indicating that linear scaling is only done if it seems required.\n",
      "     This option is only important if a linear scaling method (e.g., mc19) is\n",
      "     used.  If you choose \"no\", then the scaling factors are computed for\n",
      "     every linear system from the start.  This can be quite expensive.\n",
      "     Choosing \"yes\" means that the algorithm will start the scaling method\n",
      "     only when the solutions to the linear system seem not good, and then use\n",
      "     it until the end.\n",
      "   Possible values:\n",
      "    - no                      [Always scale the linear system.]\n",
      "    - yes                     [Start using linear system scaling if solutions\n",
      "                               seem not good.]\n",
      "\n",
      "\n",
      "\n",
      "### Step Calculation ###\n",
      "\n",
      "mehrotra_algorithm            (\"no\")\n",
      "   Indicates if we want to do Mehrotra's algorithm.\n",
      "     If set to yes, Ipopt runs as Mehrotra's predictor-corrector algorithm.\n",
      "     This works usually very well for LPs and convex QPs.  This automatically\n",
      "     disables the line search, and chooses the (unglobalized) adaptive mu\n",
      "     strategy with the \"probing\" oracle, and uses \"corrector_type=affine\"\n",
      "     without any safeguards; you should not set any of those options\n",
      "     explicitly in addition.  Also, unless otherwise specified, the values of\n",
      "     \"bound_push\", \"bound_frac\", and \"bound_mult_init_val\" are set more\n",
      "     aggressive, and sets \"alpha_for_y=bound_mult\".\n",
      "   Possible values:\n",
      "    - no                      [Do the usual Ipopt algorithm.]\n",
      "    - yes                     [Do Mehrotra's predictor-corrector algorithm.]\n",
      "\n",
      "fast_step_computation         (\"no\")\n",
      "   Indicates if the linear system should be solved quickly.\n",
      "     If set to yes, the algorithm assumes that the linear system that is\n",
      "     solved to obtain the search direction, is solved sufficiently well. In\n",
      "     that case, no residuals are computed, and the computation of the search\n",
      "     direction is a little faster.\n",
      "   Possible values:\n",
      "    - no                      [Verify solution of linear system by computing\n",
      "                               residuals.]\n",
      "    - yes                     [Trust that linear systems are solved well.]\n",
      "\n",
      "min_refinement_steps                   0 <= (          1) <  +inf      \n",
      "   Minimum number of iterative refinement steps per linear system solve.\n",
      "     Iterative refinement (on the full unsymmetric system) is performed for\n",
      "     each right hand side.  This option determines the minimum number of\n",
      "     iterative refinements (i.e. at least \"min_refinement_steps\" iterative\n",
      "     refinement steps are enforced per right hand side.)\n",
      "\n",
      "max_refinement_steps                   0 <= (         10) <  +inf      \n",
      "   Maximum number of iterative refinement steps per linear system solve.\n",
      "     Iterative refinement (on the full unsymmetric system) is performed for\n",
      "     each right hand side.  This option determines the maximum number of\n",
      "     iterative refinement steps.\n",
      "\n",
      "residual_ratio_max                     0 <  (     1e-010) <  +inf      \n",
      "   Iterative refinement tolerance\n",
      "     Iterative refinement is performed until the residual test ratio is less\n",
      "     than this tolerance (or until \"max_refinement_steps\" refinement steps are\n",
      "     performed).\n",
      "\n",
      "residual_ratio_singular                0 <  (     1e-005) <  +inf      \n",
      "   Threshold for declaring linear system singular after failed iterative\n",
      "   refinement.\n",
      "     If the residual test ratio is larger than this value after failed\n",
      "     iterative refinement, the algorithm pretends that the linear system is\n",
      "     singular.\n",
      "\n",
      "residual_improvement_factor            0 <  (          1) <  +inf      \n",
      "   Minimal required reduction of residual test ratio in iterative refinement.\n",
      "     If the improvement of the residual test ratio made by one iterative\n",
      "     refinement step is not better than this factor, iterative refinement is\n",
      "     aborted.\n",
      "\n",
      "neg_curv_test_tol                      0 <  (          0) <  +inf      \n",
      "   Tolerance for heuristic to ignore wrong inertia.\n",
      "     If positive, incorrect inertia in the augmented system is ignored, and we\n",
      "     test if the direction is a direction of positive curvature.  This\n",
      "     tolerance determines when the direction is considered to be sufficiently\n",
      "     positive.\n",
      "\n",
      "max_hessian_perturbation               0 <  (     1e+020) <  +inf      \n",
      "   Maximum value of regularization parameter for handling negative curvature.\n",
      "     In order to guarantee that the search directions are indeed proper\n",
      "     descent directions, Ipopt requires that the inertia of the (augmented)\n",
      "     linear system for the step computation has the correct number of negative\n",
      "     and positive eigenvalues. The idea is that this guides the algorithm away\n",
      "     from maximizers and makes Ipopt more likely converge to first order\n",
      "     optimal points that are minimizers. If the inertia is not correct, a\n",
      "     multiple of the identity matrix is added to the Hessian of the Lagrangian\n",
      "     in the augmented system. This parameter gives the maximum value of the\n",
      "     regularization parameter. If a regularization of that size is not enough,\n",
      "     the algorithm skips this iteration and goes to the restoration phase.\n",
      "     (This is delta_w^max in the implementation paper.)\n",
      "\n",
      "min_hessian_perturbation               0 <= (     1e-020) <  +inf      \n",
      "   Smallest perturbation of the Hessian block.\n",
      "     The size of the perturbation of the Hessian block is never selected\n",
      "     smaller than this value, unless no perturbation is necessary. (This is\n",
      "     delta_w^min in implementation paper.)\n",
      "\n",
      "perturb_inc_fact_first                 1 <  (        100) <  +inf      \n",
      "   Increase factor for x-s perturbation for very first perturbation.\n",
      "     The factor by which the perturbation is increased when a trial value was\n",
      "     not sufficient - this value is used for the computation of the very first\n",
      "     perturbation and allows a different value for for the first perturbation\n",
      "     than that used for the remaining perturbations. (This is bar_kappa_w^+ in\n",
      "     the implementation paper.)\n",
      "\n",
      "perturb_inc_fact                       1 <  (          8) <  +inf      \n",
      "   Increase factor for x-s perturbation.\n",
      "     The factor by which the perturbation is increased when a trial value was\n",
      "     not sufficient - this value is used for the computation of all\n",
      "     perturbations except for the first. (This is kappa_w^+ in the\n",
      "     implementation paper.)\n",
      "\n",
      "perturb_dec_fact                       0 <  (   0.333333) <  1         \n",
      "   Decrease factor for x-s perturbation.\n",
      "     The factor by which the perturbation is decreased when a trial value is\n",
      "     deduced from the size of the most recent successful perturbation. (This\n",
      "     is kappa_w^- in the implementation paper.)\n",
      "\n",
      "first_hessian_perturbation             0 <  (     0.0001) <  +inf      \n",
      "   Size of first x-s perturbation tried.\n",
      "     The first value tried for the x-s perturbation in the inertia correction\n",
      "     scheme.(This is delta_0 in the implementation paper.)\n",
      "\n",
      "jacobian_regularization_value          0 <= (     1e-008) <  +inf      \n",
      "   Size of the regularization for rank-deficient constraint Jacobians.\n",
      "     (This is bar delta_c in the implementation paper.)\n",
      "\n",
      "jacobian_regularization_exponent         0 <= (       0.25) <  +inf      \n",
      "   Exponent for mu in the regularization for rank-deficient constraint\n",
      "   Jacobians.\n",
      "     (This is kappa_c in the implementation paper.)\n",
      "\n",
      "perturb_always_cd             (\"no\")\n",
      "   Active permanent perturbation of constraint linearization.\n",
      "     This options makes the delta_c and delta_d perturbation be used for the\n",
      "     computation of every search direction.  Usually, it is only used when the\n",
      "     iteration matrix is singular.\n",
      "   Possible values:\n",
      "    - no                      [perturbation only used when required]\n",
      "    - yes                     [always use perturbation]\n",
      "\n",
      "\n",
      "\n",
      "### Restoration Phase ###\n",
      "\n",
      "expect_infeasible_problem     (\"no\")\n",
      "   Enable heuristics to quickly detect an infeasible problem.\n",
      "     This options is meant to activate heuristics that may speed up the\n",
      "     infeasibility determination if you expect that there is a good chance for\n",
      "     the problem to be infeasible.  In the filter line search procedure, the\n",
      "     restoration phase is called more quickly than usually, and more reduction\n",
      "     in the constraint violation is enforced before the restoration phase is\n",
      "     left. If the problem is square, this option is enabled automatically.\n",
      "   Possible values:\n",
      "    - no                      [the problem probably be feasible]\n",
      "    - yes                     [the problem has a good chance to be infeasible]\n",
      "\n",
      "expect_infeasible_problem_ctol         0 <= (      0.001) <  +inf      \n",
      "   Threshold for disabling \"expect_infeasible_problem\" option.\n",
      "     If the constraint violation becomes smaller than this threshold, the\n",
      "     \"expect_infeasible_problem\" heuristics in the filter line search are\n",
      "     disabled. If the problem is square, this options is set to 0.\n",
      "\n",
      "expect_infeasible_problem_ytol         0 <  (     1e+008) <  +inf      \n",
      "   Multiplier threshold for activating \"expect_infeasible_problem\" option.\n",
      "     If the max norm of the constraint multipliers becomes larger than this\n",
      "     value and \"expect_infeasible_problem\" is chosen, then the restoration\n",
      "     phase is entered.\n",
      "\n",
      "start_with_resto              (\"no\")\n",
      "   Tells algorithm to switch to restoration phase in first iteration.\n",
      "     Setting this option to \"yes\" forces the algorithm to switch to the\n",
      "     feasibility restoration phase in the first iteration. If the initial\n",
      "     point is feasible, the algorithm will abort with a failure.\n",
      "   Possible values:\n",
      "    - no                      [don't force start in restoration phase]\n",
      "    - yes                     [force start in restoration phase]\n",
      "\n",
      "soft_resto_pderror_reduction_factor         0 <= (     0.9999) <  +inf      \n",
      "   Required reduction in primal-dual error in the soft restoration phase.\n",
      "     The soft restoration phase attempts to reduce the primal-dual error with\n",
      "     regular steps. If the damped primal-dual step (damped only to satisfy the\n",
      "     fraction-to-the-boundary rule) is not decreasing the primal-dual error by\n",
      "     at least this factor, then the regular restoration phase is called.\n",
      "     Choosing \"0\" here disables the soft restoration phase.\n",
      "\n",
      "max_soft_resto_iters                   0 <= (         10) <  +inf      \n",
      "   Maximum number of iterations performed successively in soft restoration\n",
      "   phase.\n",
      "     If the soft restoration phase is performed for more than so many\n",
      "     iterations in a row, the regular restoration phase is called.\n",
      "\n",
      "required_infeasibility_reduction         0 <= (        0.9) <  1         \n",
      "   Required reduction of infeasibility before leaving restoration phase.\n",
      "     The restoration phase algorithm is performed, until a point is found that\n",
      "     is acceptable to the filter and the infeasibility has been reduced by at\n",
      "     least the fraction given by this option.\n",
      "\n",
      "max_resto_iter                         0 <= (    3000000) <  +inf      \n",
      "   Maximum number of successive iterations in restoration phase.\n",
      "     The algorithm terminates with an error message if the number of\n",
      "     iterations successively taken in the restoration phase exceeds this\n",
      "     number.\n",
      "\n",
      "evaluate_orig_obj_at_resto_trial(\"yes\")\n",
      "   Determines if the original objective function should be evaluated at\n",
      "   restoration phase trial points.\n",
      "     Setting this option to \"yes\" makes the restoration phase algorithm\n",
      "     evaluate the objective function of the original problem at every trial\n",
      "     point encountered during the restoration phase, even if this value is not\n",
      "     required.  In this way, it is guaranteed that the original objective\n",
      "     function can be evaluated without error at all accepted iterates;\n",
      "     otherwise the algorithm might fail at a point where the restoration phase\n",
      "     accepts an iterate that is good for the restoration phase problem, but\n",
      "     not the original problem.  On the other hand, if the evaluation of the\n",
      "     original objective is expensive, this might be costly.\n",
      "   Possible values:\n",
      "    - no                      [skip evaluation]\n",
      "    - yes                     [evaluate at every trial point]\n",
      "\n",
      "resto_penalty_parameter                0 <  (       1000) <  +inf      \n",
      "   Penalty parameter in the restoration phase objective function.\n",
      "     This is the parameter rho in equation (31a) in the Ipopt implementation\n",
      "     paper.\n",
      "\n",
      "resto_proximity_weight                 0 <= (          1) <  +inf      \n",
      "   Weighting factor for the proximity term in restoration phase objective.\n",
      "     This determines how the parameter zera in equation (29a) in the\n",
      "     implementation paper is computed.  zeta here is\n",
      "     resto_proximity_weight*sqrt(mu), where mu is the current barrier\n",
      "     parameter.\n",
      "\n",
      "bound_mult_reset_threshold             0 <= (       1000) <  +inf      \n",
      "   Threshold for resetting bound multipliers after the restoration phase.\n",
      "     After returning from the restoration phase, the bound multipliers are\n",
      "     updated with a Newton step for complementarity.  Here, the change in the\n",
      "     primal variables during the entire restoration phase is taken to be the\n",
      "     corresponding primal Newton step. However, if after the update the\n",
      "     largest bound multiplier exceeds the threshold specified by this option,\n",
      "     the multipliers are all reset to 1.\n",
      "\n",
      "constr_mult_reset_threshold            0 <= (          0) <  +inf      \n",
      "   Threshold for resetting equality and inequality multipliers after\n",
      "   restoration phase.\n",
      "     After returning from the restoration phase, the constraint multipliers\n",
      "     are recomputed by a least square estimate.  This option triggers when\n",
      "     those least-square estimates should be ignored.\n",
      "\n",
      "resto_failure_feasibility_threshold         0 <= (          0) <  +inf      \n",
      "   Threshold for primal infeasibility to declare failure of restoration phase.\n",
      "     If the restoration phase is terminated because of the \"acceptable\"\n",
      "     termination criteria and the primal infeasibility is smaller than this\n",
      "     value, the restoration phase is declared to have failed.  The default\n",
      "     value is 1e2*tol, where tol is the general termination tolerance.\n",
      "\n",
      "\n",
      "\n",
      "### Derivative Checker ###\n",
      "\n",
      "derivative_test               (\"none\")\n",
      "   Enable derivative checker\n",
      "     If this option is enabled, a (slow!) derivative test will be performed\n",
      "     before the optimization.  The test is performed at the user provided\n",
      "     starting point and marks derivative values that seem suspicious\n",
      "   Possible values:\n",
      "    - none                    [do not perform derivative test]\n",
      "    - first-order             [perform test of first derivatives at starting\n",
      "                               point]\n",
      "    - second-order            [perform test of first and second derivatives at\n",
      "                               starting point]\n",
      "    - only-second-order       [perform test of second derivatives at starting\n",
      "                               point]\n",
      "\n",
      "derivative_test_first_index           -2 <= (         -2) <  +inf      \n",
      "   Index of first quantity to be checked by derivative checker\n",
      "     If this is set to -2, then all derivatives are checked.  Otherwise, for\n",
      "     the first derivative test it specifies the first variable for which the\n",
      "     test is done (counting starts at 0).  For second derivatives, it\n",
      "     specifies the first constraint for which the test is done; counting of\n",
      "     constraint indices starts at 0, and -1 refers to the objective function\n",
      "     Hessian.\n",
      "\n",
      "derivative_test_perturbation           0 <  (     1e-008) <  +inf      \n",
      "   Size of the finite difference perturbation in derivative test.\n",
      "     This determines the relative perturbation of the variable entries.\n",
      "\n",
      "derivative_test_tol                    0 <  (     0.0001) <  +inf      \n",
      "   Threshold for indicating wrong derivative.\n",
      "     If the relative deviation of the estimated derivative from the given one\n",
      "     is larger than this value, the corresponding derivative is marked as\n",
      "     wrong.\n",
      "\n",
      "derivative_test_print_all     (\"no\")\n",
      "   Indicates whether information for all estimated derivatives should be\n",
      "   printed.\n",
      "     Determines verbosity of derivative checker.\n",
      "   Possible values:\n",
      "    - no                      [Print only suspect derivatives]\n",
      "    - yes                     [Print all derivatives]\n",
      "\n",
      "jacobian_approximation        (\"exact\")\n",
      "   Specifies technique to compute constraint Jacobian\n",
      "   Possible values:\n",
      "    - exact                   [user-provided derivatives]\n",
      "    - finite-difference-values [user-provided structure, values by finite\n",
      "                               differences]\n",
      "\n",
      "findiff_perturbation                   0 <  (     1e-007) <  +inf      \n",
      "   Size of the finite difference perturbation for derivative approximation.\n",
      "     This determines the relative perturbation of the variable entries.\n",
      "\n",
      "point_perturbation_radius              0 <= (         10) <  +inf      \n",
      "   Maximal perturbation of an evaluation point.\n",
      "     If a random perturbation of a points is required, this number indicates\n",
      "     the maximal perturbation.  This is for example used when determining the\n",
      "     center point at which the finite difference derivative test is executed.\n",
      "\n",
      "\n",
      "\n",
      "### Hessian Approximation ###\n",
      "\n",
      "limited_memory_aug_solver     (\"sherman-morrison\")\n",
      "   Strategy for solving the augmented system for low-rank Hessian.\n",
      "   Possible values:\n",
      "    - sherman-morrison        [use Sherman-Morrison formula]\n",
      "    - extended                [use an extended augmented system]\n",
      "\n",
      "limited_memory_max_history             0 <= (          6) <  +inf      \n",
      "   Maximum size of the history for the limited quasi-Newton Hessian\n",
      "   approximation.\n",
      "     This option determines the number of most recent iterations that are\n",
      "     taken into account for the limited-memory quasi-Newton approximation.\n",
      "\n",
      "limited_memory_update_type    (\"bfgs\")\n",
      "   Quasi-Newton update formula for the limited memory approximation.\n",
      "     Determines which update formula is to be used for the limited-memory\n",
      "     quasi-Newton approximation.\n",
      "   Possible values:\n",
      "    - bfgs                    [BFGS update (with skipping)]\n",
      "    - sr1                     [SR1 (not working well)]\n",
      "\n",
      "limited_memory_initialization (\"scalar1\")\n",
      "   Initialization strategy for the limited memory quasi-Newton approximation.\n",
      "     Determines how the diagonal Matrix B_0 as the first term in the limited\n",
      "     memory approximation should be computed.\n",
      "   Possible values:\n",
      "    - scalar1                 [sigma = s^Ty/s^Ts]\n",
      "    - scalar2                 [sigma = y^Ty/s^Ty]\n",
      "    - scalar3                 [arithmetic average of scalar1 and scalar2]\n",
      "    - scalar4                 [geometric average of scalar1 and scalar2]\n",
      "    - constant                [sigma = limited_memory_init_val]\n",
      "\n",
      "limited_memory_init_val                0 <  (          1) <  +inf      \n",
      "   Value for B0 in low-rank update.\n",
      "     The starting matrix in the low rank update, B0, is chosen to be this\n",
      "     multiple of the identity in the first iteration (when no updates have\n",
      "     been performed yet), and is constantly chosen as this value, if\n",
      "     \"limited_memory_initialization\" is \"constant\".\n",
      "\n",
      "limited_memory_init_val_max            0 <  (     1e+008) <  +inf      \n",
      "   Upper bound on value for B0 in low-rank update.\n",
      "     The starting matrix in the low rank update, B0, is chosen to be this\n",
      "     multiple of the identity in the first iteration (when no updates have\n",
      "     been performed yet), and is constantly chosen as this value, if\n",
      "     \"limited_memory_initialization\" is \"constant\".\n",
      "\n",
      "limited_memory_init_val_min            0 <  (     1e-008) <  +inf      \n",
      "   Lower bound on value for B0 in low-rank update.\n",
      "     The starting matrix in the low rank update, B0, is chosen to be this\n",
      "     multiple of the identity in the first iteration (when no updates have\n",
      "     been performed yet), and is constantly chosen as this value, if\n",
      "     \"limited_memory_initialization\" is \"constant\".\n",
      "\n",
      "limited_memory_max_skipping            1 <= (          2) <  +inf      \n",
      "   Threshold for successive iterations where update is skipped.\n",
      "     If the update is skipped more than this number of successive iterations,\n",
      "     we quasi-Newton approximation is reset.\n",
      "\n",
      "limited_memory_special_for_resto(\"no\")\n",
      "   Determines if the quasi-Newton updates should be special during the\n",
      "   restoration phase.\n",
      "     Until Nov 2010, Ipopt used a special update during the restoration phase,\n",
      "     but it turned out that this does not work well.  The new default uses the\n",
      "     regular update procedure and it improves results.  If for some reason you\n",
      "     want to get back to the original update, set this option to \"yes\".\n",
      "   Possible values:\n",
      "    - no                      [use the same update as in regular iterations]\n",
      "    - yes                     [use the a special update during restoration\n",
      "                               phase]\n",
      "\n",
      "hessian_approximation         (\"exact\")\n",
      "   Indicates what Hessian information is to be used.\n",
      "     This determines which kind of information for the Hessian of the\n",
      "     Lagrangian function is used by the algorithm.\n",
      "   Possible values:\n",
      "    - exact                   [Use second derivatives provided by the NLP.]\n",
      "    - limited-memory          [Perform a limited-memory quasi-Newton\n",
      "                               approximation]\n",
      "\n",
      "hessian_approximation_space   (\"nonlinear-variables\")\n",
      "   Indicates in which subspace the Hessian information is to be approximated.\n",
      "   Possible values:\n",
      "    - nonlinear-variables     [only in space of nonlinear variables.]\n",
      "    - all-variables           [in space of all variables (without slacks)]\n",
      "\n",
      "\n",
      "\n",
      "### MA27 Linear Solver ###\n",
      "\n",
      "ma27_pivtol                            0 <  (     1e-008) <  1         \n",
      "   Pivot tolerance for the linear solver MA27.\n",
      "     A smaller number pivots for sparsity, a larger number pivots for\n",
      "     stability.  This option is only available if Ipopt has been compiled with\n",
      "     MA27.\n",
      "\n",
      "ma27_pivtolmax                         0 <  (     0.0001) <  1         \n",
      "   Maximum pivot tolerance for the linear solver MA27.\n",
      "     Ipopt may increase pivtol as high as pivtolmax to get a more accurate\n",
      "     solution to the linear system.  This option is only available if Ipopt\n",
      "     has been compiled with MA27.\n",
      "\n",
      "ma27_liw_init_factor                   1 <= (          5) <  +inf      \n",
      "   Integer workspace memory for MA27.\n",
      "     The initial integer workspace memory = liw_init_factor * memory required\n",
      "     by unfactored system. Ipopt will increase the workspace size by\n",
      "     meminc_factor if required.  This option is only available if Ipopt has\n",
      "     been compiled with MA27.\n",
      "\n",
      "ma27_la_init_factor                    1 <= (          5) <  +inf      \n",
      "   Real workspace memory for MA27.\n",
      "     The initial real workspace memory = la_init_factor * memory required by\n",
      "     unfactored system. Ipopt will increase the workspace size by\n",
      "     meminc_factor if required.  This option is only available if  Ipopt has\n",
      "     been compiled with MA27.\n",
      "\n",
      "ma27_meminc_factor                     1 <= (          2) <  +inf      \n",
      "   Increment factor for workspace size for MA27.\n",
      "     If the integer or real workspace is not large enough, Ipopt will increase\n",
      "     its size by this factor.  This option is only available if Ipopt has been\n",
      "     compiled with MA27.\n",
      "\n",
      "ma27_skip_inertia_check       (\"no\")\n",
      "   Always pretend inertia is correct.\n",
      "     Setting this option to \"yes\" essentially disables inertia check. This\n",
      "     option makes the algorithm non-robust and easily fail, but it might give\n",
      "     some insight into the necessity of inertia control.\n",
      "   Possible values:\n",
      "    - no                      [check inertia]\n",
      "    - yes                     [skip inertia check]\n",
      "\n",
      "ma27_ignore_singularity       (\"no\")\n",
      "   Enables MA27's ability to solve a linear system even if the matrix is\n",
      "   singular.\n",
      "     Setting this option to \"yes\" means that Ipopt will call MA27 to compute\n",
      "     solutions for right hand sides, even if MA27 has detected that the matrix\n",
      "     is singular (but is still able to solve the linear system). In some cases\n",
      "     this might be better than using Ipopt's heuristic of small perturbation\n",
      "     of the lower diagonal of the KKT matrix.\n",
      "   Possible values:\n",
      "    - no                      [Don't have MA27 solve singular systems]\n",
      "    - yes                     [Have MA27 solve singular systems]\n",
      "\n",
      "\n",
      "\n",
      "### MA57 Linear Solver ###\n",
      "\n",
      "ma57_pivtol                            0 <  (     1e-008) <  1         \n",
      "   Pivot tolerance for the linear solver MA57.\n",
      "     A smaller number pivots for sparsity, a larger number pivots for\n",
      "     stability. This option is only available if Ipopt has been compiled with\n",
      "     MA57.\n",
      "\n",
      "ma57_pivtolmax                         0 <  (     0.0001) <  1         \n",
      "   Maximum pivot tolerance for the linear solver MA57.\n",
      "     Ipopt may increase pivtol as high as ma57_pivtolmax to get a more\n",
      "     accurate solution to the linear system.  This option is only available if\n",
      "     Ipopt has been compiled with MA57.\n",
      "\n",
      "ma57_pre_alloc                         1 <= (       1.05) <  +inf      \n",
      "   Safety factor for work space memory allocation for the linear solver MA57.\n",
      "     If 1 is chosen, the suggested amount of work space is used.  However,\n",
      "     choosing a larger number might avoid reallocation if the suggest values\n",
      "     do not suffice.  This option is only available if Ipopt has been compiled\n",
      "     with MA57.\n",
      "\n",
      "ma57_pivot_order                       0 <= (          5) <= 5         \n",
      "   Controls pivot order in MA57\n",
      "     This is ICNTL(6) in MA57.\n",
      "\n",
      "ma57_automatic_scaling        (\"no\")\n",
      "   Controls MA57 automatic scaling\n",
      "     This option controls the internal scaling option of MA57. For higher\n",
      "     reliability of the MA57 solver, you may want to set this option to yes.\n",
      "     This is ICNTL(15) in MA57.\n",
      "   Possible values:\n",
      "    - no                      [Do not scale the linear system matrix]\n",
      "    - yes                     [Scale the linear system matrix]\n",
      "\n",
      "ma57_block_size                        1 <= (         16) <  +inf      \n",
      "   Controls block size used by Level 3 BLAS in MA57BD\n",
      "     This is ICNTL(11) in MA57.\n",
      "\n",
      "ma57_node_amalgamation                 1 <= (         16) <  +inf      \n",
      "   Node amalgamation parameter\n",
      "     This is ICNTL(12) in MA57.\n",
      "\n",
      "ma57_small_pivot_flag                  0 <= (          0) <= 1         \n",
      "   If set to 1, then when small entries defined by CNTL(2) are detected they\n",
      "   are removed and the corresponding pivots placed at the end of the\n",
      "   factorization.  This can be particularly efficient if the matrix is highly\n",
      "   rank deficient.\n",
      "     This is ICNTL(16) in MA57.\n",
      "\n",
      "\n",
      "\n",
      "### Pardiso Linear Solver ###\n",
      "\n",
      "pardiso_matching_strategy     (\"complete+2x2\")\n",
      "   Matching strategy to be used by Pardiso\n",
      "     This is IPAR(13) in Pardiso manual.  This option is only available if\n",
      "     Ipopt has been compiled with Pardiso.\n",
      "   Possible values:\n",
      "    - complete                [Match complete (IPAR(13)=1)]\n",
      "    - complete+2x2            [Match complete+2x2 (IPAR(13)=2)]\n",
      "    - constraints             [Match constraints (IPAR(13)=3)]\n",
      "\n",
      "pardiso_redo_symbolic_fact_only_if_inertia_wrong(\"no\")\n",
      "   Toggle for handling case when elements were perturbed by Pardiso.\n",
      "     This option is only available if Ipopt has been compiled with Pardiso.\n",
      "   Possible values:\n",
      "    - no                      [Always redo symbolic factorization when\n",
      "                               elements were perturbed]\n",
      "    - yes                     [Only redo symbolic factorization when elements\n",
      "                               were perturbed if also the inertia was wrong]\n",
      "\n",
      "pardiso_repeated_perturbation_means_singular(\"no\")\n",
      "   Interpretation of perturbed elements.\n",
      "     This option is only available if Ipopt has been compiled with Pardiso.\n",
      "   Possible values:\n",
      "    - no                      [Don't assume that matrix is singular if\n",
      "                               elements were perturbed after recent symbolic\n",
      "                               factorization]\n",
      "    - yes                     [Assume that matrix is singular if elements were\n",
      "                               perturbed after recent symbolic factorization]\n",
      "\n",
      "pardiso_out_of_core_power              0 <= (          0) <  +inf      \n",
      "   Enables out-of-core variant of Pardiso\n",
      "     Setting this option to a positive integer k makes Pardiso work in the\n",
      "     out-of-core variant where the factor is split in 2^k subdomains.  This is\n",
      "     IPARM(50) in the Pardiso manual.  This option is only available if Ipopt\n",
      "     has been compiled with Pardiso.\n",
      "\n",
      "pardiso_msglvl                         0 <= (          0) <  +inf      \n",
      "   Pardiso message level\n",
      "     This determines the amount of analysis output from the Pardiso solver.\n",
      "     This is MSGLVL in the Pardiso manual.\n",
      "\n",
      "pardiso_skip_inertia_check    (\"no\")\n",
      "   Always pretend inertia is correct.\n",
      "     Setting this option to \"yes\" essentially disables inertia check. This\n",
      "     option makes the algorithm non-robust and easily fail, but it might give\n",
      "     some insight into the necessity of inertia control.\n",
      "   Possible values:\n",
      "    - no                      [check inertia]\n",
      "    - yes                     [skip inertia check]\n",
      "\n",
      "pardiso_max_iter                       1 <= (        500) <  +inf      \n",
      "   Maximum number of Krylov-Subspace Iteration\n",
      "     DPARM(1)\n",
      "\n",
      "pardiso_iter_relative_tol              0 <  (     1e-006) <  1         \n",
      "   Relative Residual Convergence\n",
      "     DPARM(2)\n",
      "\n",
      "pardiso_iter_coarse_size               1 <= (       5000) <  +inf      \n",
      "   Maximum Size of Coarse Grid Matrix\n",
      "     DPARM(3)\n",
      "\n",
      "pardiso_iter_max_levels                1 <= (         10) <  +inf      \n",
      "   Maximum Size of Grid Levels\n",
      "     DPARM(4)\n",
      "\n",
      "pardiso_iter_dropping_factor           0 <  (        0.5) <  1         \n",
      "   dropping value for incomplete factor\n",
      "     DPARM(5)\n",
      "\n",
      "pardiso_iter_dropping_schur            0 <  (        0.1) <  1         \n",
      "   dropping value for sparsify schur complement factor\n",
      "     DPARM(6)\n",
      "\n",
      "pardiso_iter_max_row_fill              1 <= (   10000000) <  +inf      \n",
      "   max fill for each row\n",
      "     DPARM(7)\n",
      "\n",
      "pardiso_iter_inverse_norm_factor         1 <  (     5e+006) <  +inf      \n",
      "   \n",
      "     DPARM(8)\n",
      "\n",
      "pardiso_iterative             (\"no\")\n",
      "   Switch on iterative solver in Pardiso library\n",
      "   Possible values:\n",
      "    - no                     \n",
      "    - yes                    \n",
      "\n",
      "pardiso_max_droptol_corrections         1 <= (          4) <  +inf      \n",
      "   Maximal number of decreases of drop tolerance during one solve.\n",
      "     This is relevant only for iterative Pardiso options.\n",
      "\n",
      "\n",
      "\n",
      "### Mumps Linear Solver ###\n",
      "\n",
      "mumps_pivtol                           0 <= (     1e-006) <= 1         \n",
      "   Pivot tolerance for the linear solver MUMPS.\n",
      "     A smaller number pivots for sparsity, a larger number pivots for\n",
      "     stability.  This option is only available if Ipopt has been compiled with\n",
      "     MUMPS.\n",
      "\n",
      "mumps_pivtolmax                        0 <= (        0.1) <= 1         \n",
      "   Maximum pivot tolerance for the linear solver MUMPS.\n",
      "     Ipopt may increase pivtol as high as pivtolmax to get a more accurate\n",
      "     solution to the linear system.  This option is only available if Ipopt\n",
      "     has been compiled with MUMPS.\n",
      "\n",
      "mumps_mem_percent                      0 <= (       1000) <  +inf      \n",
      "   Percentage increase in the estimated working space for MUMPS.\n",
      "     In MUMPS when significant extra fill-in is caused by numerical pivoting,\n",
      "     larger values of mumps_mem_percent may help use the workspace more\n",
      "     efficiently.  On the other hand, if memory requirement are too large at\n",
      "     the very beginning of the optimization, choosing a much smaller value for\n",
      "     this option, such as 5, might reduce memory requirements.\n",
      "\n",
      "mumps_permuting_scaling                0 <= (          7) <= 7         \n",
      "   Controls permuting and scaling in MUMPS\n",
      "     This is ICNTL(6) in MUMPS.\n",
      "\n",
      "mumps_pivot_order                      0 <= (          7) <= 7         \n",
      "   Controls pivot order in MUMPS\n",
      "     This is ICNTL(7) in MUMPS.\n",
      "\n",
      "mumps_scaling                         -2 <= (         77) <= 77        \n",
      "   Controls scaling in MUMPS\n",
      "     This is ICNTL(8) in MUMPS.\n",
      "\n",
      "mumps_dep_tol                       -inf <  (          0) <  +inf      \n",
      "   Pivot threshold for detection of linearly dependent constraints in MUMPS.\n",
      "     When MUMPS is used to determine linearly dependent constraints, this is\n",
      "     determines the threshold for a pivot to be considered zero.  This is\n",
      "     CNTL(3) in MUMPS.\n",
      "\n",
      "\n",
      "\n",
      "### MA28 Linear Solver ###\n",
      "\n",
      "ma28_pivtol                            0 <  (       0.01) <= 1         \n",
      "   Pivot tolerance for linear solver MA28.\n",
      "     This is used when MA28 tries to find the dependent constraints.\n",
      "\n",
      "\n",
      "\n",
      "### Uncategorized ###\n",
      "\n",
      "warm_start_target_mu                -inf <  (          0) <  +inf      \n",
      "   Unsupported!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ipopt --print-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Incorrect usage. Correct command syntax is:\n",
      "   cplex [-i] [-f <commandfile> | -c \"<command1>\" \"<command2>\" ...]\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "!cplex [-i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solve speed (one time step, one start states combination)\n",
    "#### conopt\n",
    "    gams: ~60 s vs. neos: ~ \n",
    "#### ipopt\n",
    "    gams: ~80 s vs. local: 18 s\n",
    "#### couenne\n",
    "    ~70 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3    C:\\Users\\leigao\\AppData\\Local\\Continuum\\anaconda3\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
